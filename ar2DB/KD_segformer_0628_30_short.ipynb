{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Position_Embedding_0628_teacher_0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 748ms/step - loss: 0.0909\n",
      "Average validation loss: 0.6447508931159973\n",
      "4/4 [==============================] - 8s 762ms/step - loss: 0.0909 - val_loss: 0.6448\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 11s 767ms/step - loss: 0.0635 - val_loss: 0.6448\n",
      "Average validation loss: 0.5469310879707336\n",
      "4/4 [==============================] - 11s 789ms/step - loss: 0.0635 - val_loss: 0.5958\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 14s 750ms/step - loss: 0.0492 - val_loss: 0.5958\n",
      "Average validation loss: 0.6272464394569397\n",
      "4/4 [==============================] - 14s 770ms/step - loss: 0.0492 - val_loss: 0.6063\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 17s 763ms/step - loss: 0.0391 - val_loss: 0.6063\n",
      "Average validation loss: 0.5252798199653625\n",
      "4/4 [==============================] - 17s 781ms/step - loss: 0.0391 - val_loss: 0.5861\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 20s 768ms/step - loss: 0.0323 - val_loss: 0.5861\n",
      "Average validation loss: 0.4125025272369385\n",
      "4/4 [==============================] - 20s 788ms/step - loss: 0.0323 - val_loss: 0.5513\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 23s 787ms/step - loss: 0.0273 - val_loss: 0.5513\n",
      "Average validation loss: 0.24111610651016235\n",
      "4/4 [==============================] - 23s 803ms/step - loss: 0.0273 - val_loss: 0.4996\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 27s 792ms/step - loss: 0.0237 - val_loss: 0.4996\n",
      "Average validation loss: 0.18121744692325592\n",
      "4/4 [==============================] - 27s 804ms/step - loss: 0.0237 - val_loss: 0.4541\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 30s 802ms/step - loss: 0.0208 - val_loss: 0.4541\n",
      "Average validation loss: 0.13085441291332245\n",
      "4/4 [==============================] - 30s 815ms/step - loss: 0.0208 - val_loss: 0.4137\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 33s 780ms/step - loss: 0.0186 - val_loss: 0.4137\n",
      "Average validation loss: 0.1079791709780693\n",
      "4/4 [==============================] - 33s 791ms/step - loss: 0.0186 - val_loss: 0.3798\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 36s 770ms/step - loss: 0.0168 - val_loss: 0.3798\n",
      "Average validation loss: 0.08934537321329117\n",
      "4/4 [==============================] - 36s 785ms/step - loss: 0.0168 - val_loss: 0.3507\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Train loss: 0.016807958230492658, Validation loss: 0.3507223278284073\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0077\n",
      "Average validation loss: 0.0004072256851941347\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0077 - val_loss: 4.0723e-04\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 776ms/step - loss: 0.0048 - val_loss: 4.0723e-04\n",
      "Average validation loss: 0.002034332137554884\n",
      "4/4 [==============================] - 6s 788ms/step - loss: 0.0048 - val_loss: 0.0012    \n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 10s 795ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Average validation loss: 0.10948415845632553\n",
      "4/4 [==============================] - 10s 808ms/step - loss: 0.0034 - val_loss: 0.0373\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 13s 805ms/step - loss: 0.0027 - val_loss: 0.0373\n",
      "Average validation loss: 0.3186679780483246\n",
      "4/4 [==============================] - 13s 818ms/step - loss: 0.0027 - val_loss: 0.1076\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 16s 760ms/step - loss: 0.0022 - val_loss: 0.1076\n",
      "Average validation loss: 0.392736554145813\n",
      "4/4 [==============================] - 16s 773ms/step - loss: 0.0022 - val_loss: 0.1647\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 19s 696ms/step - loss: 0.0019 - val_loss: 0.1647\n",
      "Average validation loss: 0.03018708899617195\n",
      "4/4 [==============================] - 19s 707ms/step - loss: 0.0019 - val_loss: 0.1423\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 21s 693ms/step - loss: 0.0016 - val_loss: 0.1423\n",
      "Average validation loss: 0.013949624262750149\n",
      "4/4 [==============================] - 22s 705ms/step - loss: 0.0016 - val_loss: 0.1239\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 24s 700ms/step - loss: 0.0014 - val_loss: 0.1239\n",
      "Average validation loss: 0.009464802220463753\n",
      "4/4 [==============================] - 24s 712ms/step - loss: 0.0014 - val_loss: 0.1096\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 27s 694ms/step - loss: 0.0013 - val_loss: 0.1096\n",
      "Average validation loss: 0.006093876902014017\n",
      "4/4 [==============================] - 27s 710ms/step - loss: 0.0013 - val_loss: 0.0981\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 30s 700ms/step - loss: 0.0012 - val_loss: 0.0981\n",
      "Average validation loss: 0.010729912668466568\n",
      "4/4 [==============================] - 30s 710ms/step - loss: 0.0012 - val_loss: 0.0894\n",
      "Train loss: 0.0011651184500806266, Validation loss: 0.08937555535230786\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 5.6131e-05\n",
      "Average validation loss: 0.00324840284883976\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 5.6131e-05 - val_loss: 0.0032\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 723ms/step - loss: 4.2994e-05 - val_loss: 0.0032\n",
      "Average validation loss: 0.0001765311462804675\n",
      "4/4 [==============================] - 6s 739ms/step - loss: 4.2994e-05 - val_loss: 0.0017\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 9s 689ms/step - loss: 3.5705e-05 - val_loss: 0.0017\n",
      "Average validation loss: 0.028809968382120132\n",
      "4/4 [==============================] - 9s 706ms/step - loss: 3.5705e-05 - val_loss: 0.0107\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 11s 699ms/step - loss: 3.0743e-05 - val_loss: 0.0107\n",
      "Average validation loss: 0.07641379535198212\n",
      "4/4 [==============================] - 11s 709ms/step - loss: 3.0743e-05 - val_loss: 0.0272\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 14s 689ms/step - loss: 2.7462e-05 - val_loss: 0.0272\n",
      "Average validation loss: 0.0028235106728971004\n",
      "4/4 [==============================] - 14s 701ms/step - loss: 2.7462e-05 - val_loss: 0.0223\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 17s 688ms/step - loss: 2.5111e-05 - val_loss: 0.0223\n",
      "Average validation loss: 0.00013888049579691142\n",
      "4/4 [==============================] - 17s 702ms/step - loss: 2.5111e-05 - val_loss: 0.0186\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 20s 707ms/step - loss: 2.3303e-05 - val_loss: 0.0186\n",
      "Average validation loss: 0.00048120919382199645\n",
      "4/4 [==============================] - 20s 718ms/step - loss: 2.3303e-05 - val_loss: 0.0160\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 23s 690ms/step - loss: 2.1773e-05 - val_loss: 0.0160\n",
      "Average validation loss: 0.0014683097833767533\n",
      "4/4 [==============================] - 23s 700ms/step - loss: 2.1773e-05 - val_loss: 0.0142\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 26s 688ms/step - loss: 2.0511e-05 - val_loss: 0.0142\n",
      "Average validation loss: 0.006513838656246662\n",
      "4/4 [==============================] - 26s 695ms/step - loss: 2.0511e-05 - val_loss: 0.0133\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 28s 674ms/step - loss: 1.9487e-05 - val_loss: 0.0133\n",
      "Average validation loss: 0.0106737669557333\n",
      "4/4 [==============================] - 28s 694ms/step - loss: 1.9487e-05 - val_loss: 0.0131\n",
      "Train loss: 1.9486625416220704e-05, Validation loss: 0.01307482134870952\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 4.8042e-08\n",
      "Average validation loss: 0.04186289384961128\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 4.8042e-08 - val_loss: 0.0419\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 728ms/step - loss: 4.1776e-06 - val_loss: 0.0419\n",
      "Average validation loss: 0.16620111465454102\n",
      "4/4 [==============================] - 6s 741ms/step - loss: 4.1776e-06 - val_loss: 0.1040\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 8s 695ms/step - loss: 2.7919e-06 - val_loss: 0.1040\n",
      "Average validation loss: 0.24413743615150452\n",
      "4/4 [==============================] - 9s 707ms/step - loss: 2.7919e-06 - val_loss: 0.1507\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 11s 699ms/step - loss: 2.0981e-06 - val_loss: 0.1507\n",
      "Average validation loss: 0.20860491693019867\n",
      "4/4 [==============================] - 11s 708ms/step - loss: 2.0981e-06 - val_loss: 0.1652\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 14s 690ms/step - loss: 1.6820e-06 - val_loss: 0.1652\n",
      "Average validation loss: 0.16861580312252045\n",
      "4/4 [==============================] - 14s 707ms/step - loss: 1.6820e-06 - val_loss: 0.1659\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 17s 693ms/step - loss: 1.4650e-06 - val_loss: 0.1659\n",
      "Average validation loss: 0.16661612689495087\n",
      "4/4 [==============================] - 17s 706ms/step - loss: 1.4650e-06 - val_loss: 0.1660\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 20s 701ms/step - loss: 1.2628e-06 - val_loss: 0.1660\n",
      "Average validation loss: 0.16162686049938202\n",
      "4/4 [==============================] - 20s 718ms/step - loss: 1.2628e-06 - val_loss: 0.1654\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 23s 688ms/step - loss: 1.1098e-06 - val_loss: 0.1654\n",
      "Average validation loss: 0.13350458443164825\n",
      "4/4 [==============================] - 23s 701ms/step - loss: 1.1098e-06 - val_loss: 0.1614\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 25s 695ms/step - loss: 9.8927e-07 - val_loss: 0.1614\n",
      "Average validation loss: 0.1105828732252121\n",
      "4/4 [==============================] - 25s 707ms/step - loss: 9.8927e-07 - val_loss: 0.1558\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 28s 683ms/step - loss: 8.9355e-07 - val_loss: 0.1558\n",
      "Average validation loss: 0.1176404282450676\n",
      "4/4 [==============================] - 28s 695ms/step - loss: 8.9355e-07 - val_loss: 0.1519\n",
      "Train loss: 8.935508557517124e-07, Validation loss: 0.15193930380046367\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 9.6329e-06\n",
      "Average validation loss: 0.00032252108212560415\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 9.6329e-06 - val_loss: 3.2252e-04\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 679ms/step - loss: 9.3874e-06 - val_loss: 3.2252e-04\n",
      "Average validation loss: 0.0004404763167258352\n",
      "4/4 [==============================] - 6s 695ms/step - loss: 9.3874e-06 - val_loss: 3.8150e-04\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 8s 694ms/step - loss: 9.3372e-06 - val_loss: 3.8150e-04\n",
      "Average validation loss: 0.0004340863670222461\n",
      "4/4 [==============================] - 8s 707ms/step - loss: 9.3372e-06 - val_loss: 3.9903e-04\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 11s 695ms/step - loss: 9.3179e-06 - val_loss: 3.9903e-04\n",
      "Average validation loss: 0.00029255030676722527\n",
      "4/4 [==============================] - 11s 707ms/step - loss: 9.3179e-06 - val_loss: 3.7241e-04\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_5.pth'.\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 14s 718ms/step - loss: 9.2822e-06 - val_loss: 3.7241e-04\n",
      "Average validation loss: 0.0011185487965121865\n",
      "4/4 [==============================] - 14s 729ms/step - loss: 9.2822e-06 - val_loss: 5.2164e-04\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 17s 698ms/step - loss: 9.2470e-06 - val_loss: 5.2164e-04\n",
      "Average validation loss: 0.0030876006931066513\n",
      "4/4 [==============================] - 17s 711ms/step - loss: 9.2470e-06 - val_loss: 9.4930e-04\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 20s 682ms/step - loss: 9.2228e-06 - val_loss: 9.4930e-04\n",
      "Average validation loss: 0.003259222721680999\n",
      "4/4 [==============================] - 20s 701ms/step - loss: 9.2228e-06 - val_loss: 0.0013    \n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 23s 672ms/step - loss: 9.1966e-06 - val_loss: 0.0013\n",
      "Average validation loss: 0.006800520233809948\n",
      "4/4 [==============================] - 23s 688ms/step - loss: 9.1966e-06 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 25s 700ms/step - loss: 9.1643e-06 - val_loss: 0.0020\n",
      "Average validation loss: 0.00787470955401659\n",
      "4/4 [==============================] - 25s 710ms/step - loss: 9.1643e-06 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 28s 706ms/step - loss: 9.1365e-06 - val_loss: 0.0026\n",
      "Average validation loss: 0.0022017876617610455\n",
      "4/4 [==============================] - 28s 718ms/step - loss: 9.1365e-06 - val_loss: 0.0026\n",
      "Train loss: 9.136474839777087e-06, Validation loss: 0.002583202373352833\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "1/8 [==>...........................] - ETA: 4s - loss: 3.8766e-09"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 721ms/step - loss: 4.4321e-05\n",
      "Average validation loss: 7.86207128840033e-05\n",
      "8/8 [==============================] - 6s 733ms/step - loss: 4.4321e-05 - val_loss: 7.8621e-05\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 12s 719ms/step - loss: 4.3601e-05 - val_loss: 7.8621e-05\n",
      "Average validation loss: 1.778797377482988e-05\n",
      "8/8 [==============================] - 12s 731ms/step - loss: 4.3601e-05 - val_loss: 4.8204e-05\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 698ms/step - loss: 4.2782e-05 - val_loss: 4.8204e-05\n",
      "Average validation loss: 0.002605685731396079\n",
      "8/8 [==============================] - 17s 710ms/step - loss: 4.2782e-05 - val_loss: 9.0070e-04\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 717ms/step - loss: 4.2130e-05 - val_loss: 9.0070e-04\n",
      "Average validation loss: 0.00011292891940684058\n",
      "8/8 [==============================] - 23s 726ms/step - loss: 4.2130e-05 - val_loss: 7.0376e-04\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 29s 764ms/step - loss: 4.1887e-05 - val_loss: 7.0376e-04\n",
      "Average validation loss: 0.007250186055898666\n",
      "8/8 [==============================] - 29s 775ms/step - loss: 4.1887e-05 - val_loss: 0.0020    \n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 35s 711ms/step - loss: 4.1708e-05 - val_loss: 0.0020\n",
      "Average validation loss: 0.00010159254088648595\n",
      "8/8 [==============================] - 35s 722ms/step - loss: 4.1708e-05 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 41s 710ms/step - loss: 4.1469e-05 - val_loss: 0.0017\n",
      "Average validation loss: 6.642182779614814e-05\n",
      "8/8 [==============================] - 41s 722ms/step - loss: 4.1469e-05 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 46s 700ms/step - loss: 4.1278e-05 - val_loss: 0.0015\n",
      "Average validation loss: 2.026863114679145e-06\n",
      "8/8 [==============================] - 46s 714ms/step - loss: 4.1278e-05 - val_loss: 0.0013\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 52s 705ms/step - loss: 4.1181e-05 - val_loss: 0.0013\n",
      "Average validation loss: 3.1115306228457484e-05\n",
      "8/8 [==============================] - 52s 717ms/step - loss: 4.1181e-05 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 58s 686ms/step - loss: 4.1061e-05 - val_loss: 0.0011\n",
      "Average validation loss: 1.2364553185761906e-06\n",
      "8/8 [==============================] - 58s 700ms/step - loss: 4.1061e-05 - val_loss: 0.0010\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Train loss: 4.106054753976185e-05, Validation loss: 0.0010267602386704767\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 5s 678ms/step - loss: 2.9252e-05\n",
      "Average validation loss: 0.42177796363830566\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 2.9252e-05 - val_loss: 0.4218\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 690ms/step - loss: 2.8635e-05 - val_loss: 0.4218\n",
      "Average validation loss: 0.2578619569540024\n",
      "8/8 [==============================] - 11s 705ms/step - loss: 2.8635e-05 - val_loss: 0.3398\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 684ms/step - loss: 2.8491e-05 - val_loss: 0.3398\n",
      "Average validation loss: 0.16336122900247574\n",
      "8/8 [==============================] - 17s 698ms/step - loss: 2.8491e-05 - val_loss: 0.2810\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 22s 696ms/step - loss: 2.8377e-05 - val_loss: 0.2810\n",
      "Average validation loss: 0.03696500509977341\n",
      "8/8 [==============================] - 22s 708ms/step - loss: 2.8377e-05 - val_loss: 0.2200\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 28s 695ms/step - loss: 2.8494e-05 - val_loss: 0.2200\n",
      "Average validation loss: 0.13147501647472382\n",
      "8/8 [==============================] - 28s 707ms/step - loss: 2.8494e-05 - val_loss: 0.2023\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 34s 704ms/step - loss: 2.8378e-05 - val_loss: 0.2023\n",
      "Average validation loss: 0.11591320484876633\n",
      "8/8 [==============================] - 34s 714ms/step - loss: 2.8378e-05 - val_loss: 0.1879\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 39s 702ms/step - loss: 2.8314e-05 - val_loss: 0.1879\n",
      "Average validation loss: 0.11239193007349968\n",
      "8/8 [==============================] - 39s 714ms/step - loss: 2.8314e-05 - val_loss: 0.1771\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 45s 688ms/step - loss: 2.8216e-05 - val_loss: 0.1771\n",
      "Average validation loss: 0.07061552628874779\n",
      "8/8 [==============================] - 45s 698ms/step - loss: 2.8216e-05 - val_loss: 0.1638\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 51s 716ms/step - loss: 2.8108e-05 - val_loss: 0.1638\n",
      "Average validation loss: 0.10338350757956505\n",
      "8/8 [==============================] - 51s 726ms/step - loss: 2.8108e-05 - val_loss: 0.1571\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 57s 757ms/step - loss: 2.8016e-05 - val_loss: 0.1571\n",
      "Average validation loss: 0.032878910191357136\n",
      "8/8 [==============================] - 57s 767ms/step - loss: 2.8016e-05 - val_loss: 0.1447\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Train loss: 2.8016268796500836e-05, Validation loss: 0.1446624250151217\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 3.4186e-05\n",
      "Average validation loss: 0.02217267476953566\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 3.4186e-05 - val_loss: 0.0222\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 703ms/step - loss: 3.4190e-05 - val_loss: 0.0222\n",
      "Average validation loss: 0.03267745142875356\n",
      "8/8 [==============================] - 11s 713ms/step - loss: 3.4190e-05 - val_loss: 0.0274\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 712ms/step - loss: 3.3970e-05 - val_loss: 0.0274\n",
      "Average validation loss: 0.02079720818437636\n",
      "8/8 [==============================] - 17s 721ms/step - loss: 3.3970e-05 - val_loss: 0.0252\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 710ms/step - loss: 3.3755e-05 - val_loss: 0.0252\n",
      "Average validation loss: 0.08227166950246101\n",
      "8/8 [==============================] - 23s 724ms/step - loss: 3.3755e-05 - val_loss: 0.0395\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 28s 704ms/step - loss: 3.3689e-05 - val_loss: 0.0395\n",
      "Average validation loss: 0.06857853691417404\n",
      "8/8 [==============================] - 29s 717ms/step - loss: 3.3689e-05 - val_loss: 0.0453\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 34s 698ms/step - loss: 3.3631e-05 - val_loss: 0.0453\n",
      "Average validation loss: 0.05217668826753652\n",
      "8/8 [==============================] - 34s 707ms/step - loss: 3.3631e-05 - val_loss: 0.0464\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 736ms/step - loss: 3.3498e-05 - val_loss: 0.0464\n",
      "Average validation loss: 0.071948120583329\n",
      "8/8 [==============================] - 40s 748ms/step - loss: 3.3498e-05 - val_loss: 0.0501\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 46s 703ms/step - loss: 3.3353e-05 - val_loss: 0.0501\n",
      "Average validation loss: 0.07170281757134944\n",
      "8/8 [==============================] - 46s 715ms/step - loss: 3.3353e-05 - val_loss: 0.0528\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 51s 695ms/step - loss: 3.3266e-05 - val_loss: 0.0528\n",
      "Average validation loss: 0.043953572981990874\n",
      "8/8 [==============================] - 51s 704ms/step - loss: 3.3266e-05 - val_loss: 0.0518\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 57s 705ms/step - loss: 3.3205e-05 - val_loss: 0.0518\n",
      "Average validation loss: 0.06400144372287286\n",
      "8/8 [==============================] - 57s 717ms/step - loss: 3.3205e-05 - val_loss: 0.0530\n",
      "Train loss: 3.3204650778714814e-05, Validation loss: 0.05302801839263793\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 705ms/step - loss: 2.2799e-05\n",
      "Average validation loss: 0.07885769382119179\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 2.2799e-05 - val_loss: 0.0789\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 690ms/step - loss: 2.2348e-05 - val_loss: 0.0789\n",
      "Average validation loss: 0.1686580404639244\n",
      "8/8 [==============================] - 11s 702ms/step - loss: 2.2348e-05 - val_loss: 0.1238\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 705ms/step - loss: 2.1987e-05 - val_loss: 0.1238\n",
      "Average validation loss: 0.09261687099933624\n",
      "8/8 [==============================] - 17s 717ms/step - loss: 2.1987e-05 - val_loss: 0.1134\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 697ms/step - loss: 2.1883e-05 - val_loss: 0.1134\n",
      "Average validation loss: 0.17311463877558708\n",
      "8/8 [==============================] - 23s 709ms/step - loss: 2.1883e-05 - val_loss: 0.1283\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 28s 706ms/step - loss: 2.1813e-05 - val_loss: 0.1283\n",
      "Average validation loss: 0.08745289780199528\n",
      "8/8 [==============================] - 28s 721ms/step - loss: 2.1813e-05 - val_loss: 0.1201\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 34s 743ms/step - loss: 2.1784e-05 - val_loss: 0.1201\n",
      "Average validation loss: 0.047241345047950745\n",
      "8/8 [==============================] - 34s 753ms/step - loss: 2.1784e-05 - val_loss: 0.1080\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 712ms/step - loss: 2.1640e-05 - val_loss: 0.1080\n",
      "Average validation loss: 0.18431493267416954\n",
      "8/8 [==============================] - 40s 726ms/step - loss: 2.1640e-05 - val_loss: 0.1189\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 46s 709ms/step - loss: 2.1477e-05 - val_loss: 0.1189\n",
      "Average validation loss: 0.06419763900339603\n",
      "8/8 [==============================] - 46s 720ms/step - loss: 2.1477e-05 - val_loss: 0.1121\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 51s 705ms/step - loss: 2.1228e-05 - val_loss: 0.1121\n",
      "Average validation loss: 0.06344278156757355\n",
      "8/8 [==============================] - 52s 717ms/step - loss: 2.1228e-05 - val_loss: 0.1067\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 57s 702ms/step - loss: 2.1591e-05 - val_loss: 0.1067\n",
      "Average validation loss: 0.2575048878788948\n",
      "8/8 [==============================] - 57s 713ms/step - loss: 2.1591e-05 - val_loss: 0.1217\n",
      "Train loss: 2.1590505424851428e-05, Validation loss: 0.12174017280340195\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 3.2823e-05\n",
      "Average validation loss: 0.1115267187107154\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 3.2823e-05 - val_loss: 0.1115\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 698ms/step - loss: 3.2464e-05 - val_loss: 0.1115\n",
      "Average validation loss: 0.04692769840033861\n",
      "8/8 [==============================] - 11s 709ms/step - loss: 3.2464e-05 - val_loss: 0.0792\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 707ms/step - loss: 3.1991e-05 - val_loss: 0.0792\n",
      "Average validation loss: 0.09355256615526741\n",
      "8/8 [==============================] - 17s 720ms/step - loss: 3.1991e-05 - val_loss: 0.0840\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 700ms/step - loss: 3.1863e-05 - val_loss: 0.0840\n",
      "Average validation loss: 0.038468122988433606\n",
      "8/8 [==============================] - 23s 711ms/step - loss: 3.1863e-05 - val_loss: 0.0726\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 28s 697ms/step - loss: 3.2232e-05 - val_loss: 0.0726\n",
      "Average validation loss: 0.082002499972603\n",
      "8/8 [==============================] - 28s 709ms/step - loss: 3.2232e-05 - val_loss: 0.0745\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 34s 701ms/step - loss: 3.2463e-05 - val_loss: 0.0745\n",
      "Average validation loss: 0.10226325019630167\n",
      "8/8 [==============================] - 34s 712ms/step - loss: 3.2463e-05 - val_loss: 0.0791\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 702ms/step - loss: 3.2331e-05 - val_loss: 0.0791\n",
      "Average validation loss: 0.13002529755914338\n",
      "8/8 [==============================] - 40s 714ms/step - loss: 3.2331e-05 - val_loss: 0.0864\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 45s 702ms/step - loss: 3.2516e-05 - val_loss: 0.0864\n",
      "Average validation loss: 0.030788383167418942\n",
      "8/8 [==============================] - 45s 716ms/step - loss: 3.2516e-05 - val_loss: 0.0794\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 51s 711ms/step - loss: 3.2443e-05 - val_loss: 0.0794\n",
      "Average validation loss: 0.022731841847416945\n",
      "8/8 [==============================] - 51s 721ms/step - loss: 3.2443e-05 - val_loss: 0.0731\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_10.pth'.\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 57s 698ms/step - loss: 3.2523e-05 - val_loss: 0.0731\n",
      "Average validation loss: 0.05073111885485204\n",
      "8/8 [==============================] - 57s 712ms/step - loss: 3.2523e-05 - val_loss: 0.0709\n",
      "Train loss: 3.252325981903045e-05, Validation loss: 0.0709017497852491\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      " 1/80 [..............................] - ETA: 54s - loss: 1.1194e-07"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 56s 703ms/step - loss: 3.9460e-04\n",
      "Average validation loss: 0.3299767762422562\n",
      "80/80 [==============================] - 57s 713ms/step - loss: 3.9460e-04 - val_loss: 0.3300\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 113s 702ms/step - loss: 3.6932e-04 - val_loss: 0.3300\n",
      "Average validation loss: 0.08178938012570143\n",
      "80/80 [==============================] - 114s 712ms/step - loss: 3.6932e-04 - val_loss: 0.2059\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 171s 705ms/step - loss: 3.4695e-04 - val_loss: 0.2059\n",
      "Average validation loss: 0.14705586433410645\n",
      "80/80 [==============================] - 171s 716ms/step - loss: 3.4695e-04 - val_loss: 0.1863\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 228s 707ms/step - loss: 3.5147e-04 - val_loss: 0.1863\n",
      "Average validation loss: 0.10282471217215061\n",
      "80/80 [==============================] - 229s 717ms/step - loss: 3.5147e-04 - val_loss: 0.1654\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 285s 700ms/step - loss: 3.5879e-04 - val_loss: 0.1654\n",
      "Average validation loss: 0.45691056177020073\n",
      "80/80 [==============================] - 286s 710ms/step - loss: 3.5879e-04 - val_loss: 0.2237\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 341s 699ms/step - loss: 3.4849e-04 - val_loss: 0.2237\n",
      "Average validation loss: 0.10442430060356855\n",
      "80/80 [==============================] - 342s 708ms/step - loss: 3.4849e-04 - val_loss: 0.2038\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 399s 705ms/step - loss: 3.3676e-04 - val_loss: 0.2038\n",
      "Average validation loss: 0.16578624658286573\n",
      "80/80 [==============================] - 399s 715ms/step - loss: 3.3676e-04 - val_loss: 0.1984\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 456s 704ms/step - loss: 3.2286e-04 - val_loss: 0.1984\n",
      "Average validation loss: 0.10001415330916644\n",
      "80/80 [==============================] - 456s 714ms/step - loss: 3.2286e-04 - val_loss: 0.1861\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 513s 702ms/step - loss: 3.0663e-04 - val_loss: 0.1861\n",
      "Average validation loss: 0.047453539166599515\n",
      "80/80 [==============================] - 513s 712ms/step - loss: 3.0663e-04 - val_loss: 0.1707\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 570s 704ms/step - loss: 2.9293e-04 - val_loss: 0.1707\n",
      "Average validation loss: 0.03713655825704336\n",
      "80/80 [==============================] - 570s 714ms/step - loss: 2.9293e-04 - val_loss: 0.1573\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Train loss: 0.0002929293090427798, Validation loss: 0.1573372092563659\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 57s 707ms/step - loss: 1.5154e-04\n",
      "Average validation loss: 0.045555366296321155\n",
      "80/80 [==============================] - 57s 718ms/step - loss: 1.5154e-04 - val_loss: 0.0456\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 113s 697ms/step - loss: 1.5418e-04 - val_loss: 0.0456\n",
      "Average validation loss: 0.05746405143290758\n",
      "80/80 [==============================] - 114s 707ms/step - loss: 1.5418e-04 - val_loss: 0.0515\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 171s 712ms/step - loss: 1.5099e-04 - val_loss: 0.0515\n",
      "Average validation loss: 0.0410542756319046\n",
      "80/80 [==============================] - 172s 723ms/step - loss: 1.5099e-04 - val_loss: 0.0480\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 228s 707ms/step - loss: 1.4625e-04 - val_loss: 0.0480\n",
      "Average validation loss: 0.044889208814129236\n",
      "80/80 [==============================] - 229s 716ms/step - loss: 1.4625e-04 - val_loss: 0.0472\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 285s 706ms/step - loss: 1.4182e-04 - val_loss: 0.0472\n",
      "Average validation loss: 0.044649701844900844\n",
      "80/80 [==============================] - 286s 716ms/step - loss: 1.4182e-04 - val_loss: 0.0467\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 342s 703ms/step - loss: 1.3841e-04 - val_loss: 0.0467\n",
      "Average validation loss: 0.07474104091525077\n",
      "80/80 [==============================] - 343s 713ms/step - loss: 1.3841e-04 - val_loss: 0.0514\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 400s 703ms/step - loss: 1.3563e-04 - val_loss: 0.0514\n",
      "Average validation loss: 0.04563511167652905\n",
      "80/80 [==============================] - 400s 713ms/step - loss: 1.3563e-04 - val_loss: 0.0506\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 457s 704ms/step - loss: 1.3713e-04 - val_loss: 0.0506\n",
      "Average validation loss: 0.03980136066675186\n",
      "80/80 [==============================] - 457s 714ms/step - loss: 1.3713e-04 - val_loss: 0.0492\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 514s 703ms/step - loss: 1.3583e-04 - val_loss: 0.0492\n",
      "Average validation loss: 0.03600798915140331\n",
      "80/80 [==============================] - 514s 713ms/step - loss: 1.3583e-04 - val_loss: 0.0478\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 573s 732ms/step - loss: 1.3277e-04 - val_loss: 0.0478\n",
      "Average validation loss: 0.05468048397451639\n",
      "80/80 [==============================] - 574s 744ms/step - loss: 1.3277e-04 - val_loss: 0.0484\n",
      "Train loss: 0.00013276631399606942, Validation loss: 0.048447859040461484\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 63s 792ms/step - loss: 1.1089e-04\n",
      "Average validation loss: 0.0630988027434796\n",
      "80/80 [==============================] - 64s 803ms/step - loss: 1.1089e-04 - val_loss: 0.0631\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 126s 776ms/step - loss: 1.0943e-04 - val_loss: 0.0631\n",
      "Average validation loss: 0.04303731098771095\n",
      "80/80 [==============================] - 127s 786ms/step - loss: 1.0943e-04 - val_loss: 0.0531\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 184s 708ms/step - loss: 1.0957e-04 - val_loss: 0.0531\n",
      "Average validation loss: 0.04707621829584241\n",
      "80/80 [==============================] - 185s 718ms/step - loss: 1.0957e-04 - val_loss: 0.0511\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 241s 707ms/step - loss: 1.0892e-04 - val_loss: 0.0511\n",
      "Average validation loss: 0.036094982735812665\n",
      "80/80 [==============================] - 242s 717ms/step - loss: 1.0892e-04 - val_loss: 0.0473\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 299s 707ms/step - loss: 1.0914e-04 - val_loss: 0.0473\n",
      "Average validation loss: 0.037907500367145984\n",
      "80/80 [==============================] - 299s 717ms/step - loss: 1.0914e-04 - val_loss: 0.0454\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 356s 704ms/step - loss: 1.0782e-04 - val_loss: 0.0454\n",
      "Average validation loss: 0.04672061540186405\n",
      "80/80 [==============================] - 356s 714ms/step - loss: 1.0782e-04 - val_loss: 0.0457\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 413s 707ms/step - loss: 1.0774e-04 - val_loss: 0.0457\n",
      "Average validation loss: 0.037878816155716775\n",
      "80/80 [==============================] - 414s 717ms/step - loss: 1.0774e-04 - val_loss: 0.0445\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 471s 720ms/step - loss: 1.0700e-04 - val_loss: 0.0445\n",
      "Average validation loss: 0.0401479588355869\n",
      "80/80 [==============================] - 472s 730ms/step - loss: 1.0700e-04 - val_loss: 0.0440\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 529s 707ms/step - loss: 1.0633e-04 - val_loss: 0.0440\n",
      "Average validation loss: 0.06650252547115088\n",
      "80/80 [==============================] - 530s 717ms/step - loss: 1.0633e-04 - val_loss: 0.0465\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 586s 704ms/step - loss: 1.0566e-04 - val_loss: 0.0465\n",
      "Average validation loss: 0.06516685213136952\n",
      "80/80 [==============================] - 587s 713ms/step - loss: 1.0566e-04 - val_loss: 0.0484\n",
      "Train loss: 0.00010565520483664769, Validation loss: 0.048363158312567975\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 56s 701ms/step - loss: 9.3582e-05\n",
      "Average validation loss: 0.03432098882040009\n",
      "80/80 [==============================] - 57s 711ms/step - loss: 9.3582e-05 - val_loss: 0.0343\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 114s 709ms/step - loss: 9.2220e-05 - val_loss: 0.0343\n",
      "Average validation loss: 0.046960174571722746\n",
      "80/80 [==============================] - 115s 720ms/step - loss: 9.2220e-05 - val_loss: 0.0406\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 171s 703ms/step - loss: 8.9062e-05 - val_loss: 0.0406\n",
      "Average validation loss: 0.03476799633353948\n",
      "80/80 [==============================] - 172s 713ms/step - loss: 8.9062e-05 - val_loss: 0.0387\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 229s 711ms/step - loss: 8.8150e-05 - val_loss: 0.0387\n",
      "Average validation loss: 0.04536756633315235\n",
      "80/80 [==============================] - 229s 721ms/step - loss: 8.8150e-05 - val_loss: 0.0404\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 286s 703ms/step - loss: 8.7275e-05 - val_loss: 0.0404\n",
      "Average validation loss: 0.0434575731982477\n",
      "80/80 [==============================] - 286s 713ms/step - loss: 8.7275e-05 - val_loss: 0.0410\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 343s 708ms/step - loss: 8.5945e-05 - val_loss: 0.0410\n",
      "Average validation loss: 0.04589077531127259\n",
      "80/80 [==============================] - 344s 718ms/step - loss: 8.5945e-05 - val_loss: 0.0418\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 401s 710ms/step - loss: 9.1090e-05 - val_loss: 0.0418\n",
      "Average validation loss: 0.052534401224693286\n",
      "80/80 [==============================] - 401s 720ms/step - loss: 9.1090e-05 - val_loss: 0.0433\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 458s 701ms/step - loss: 9.3050e-05 - val_loss: 0.0433\n",
      "Average validation loss: 0.05252921447827248\n",
      "80/80 [==============================] - 458s 712ms/step - loss: 9.3050e-05 - val_loss: 0.0445\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 515s 703ms/step - loss: 9.2364e-05 - val_loss: 0.0445\n",
      "Average validation loss: 0.04242811452131719\n",
      "80/80 [==============================] - 515s 713ms/step - loss: 9.2364e-05 - val_loss: 0.0443\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 572s 701ms/step - loss: 9.1309e-05 - val_loss: 0.0443\n",
      "Average validation loss: 0.03479145371820778\n",
      "80/80 [==============================] - 572s 711ms/step - loss: 9.1309e-05 - val_loss: 0.0433\n",
      "Train loss: 9.13087790143921e-05, Validation loss: 0.04330482585108257\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 57s 711ms/step - loss: 9.0793e-05\n",
      "Average validation loss: 0.0586294034961611\n",
      "80/80 [==============================] - 58s 721ms/step - loss: 9.0793e-05 - val_loss: 0.0586\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 114s 702ms/step - loss: 8.9017e-05 - val_loss: 0.0586\n",
      "Average validation loss: 0.03339944160543382\n",
      "80/80 [==============================] - 115s 712ms/step - loss: 8.9017e-05 - val_loss: 0.0460\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_100.pth'.\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 173s 725ms/step - loss: 8.6948e-05 - val_loss: 0.0460\n",
      "Average validation loss: 0.03851185035891831\n",
      "80/80 [==============================] - 174s 735ms/step - loss: 8.6948e-05 - val_loss: 0.0435\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 230s 700ms/step - loss: 8.5907e-05 - val_loss: 0.0435\n",
      "Average validation loss: 0.040801744302734734\n",
      "80/80 [==============================] - 230s 710ms/step - loss: 8.5907e-05 - val_loss: 0.0428\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 287s 701ms/step - loss: 8.5455e-05 - val_loss: 0.0428\n",
      "Average validation loss: 0.05602270867675543\n",
      "80/80 [==============================] - 287s 710ms/step - loss: 8.5455e-05 - val_loss: 0.0455\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 343s 699ms/step - loss: 8.5042e-05 - val_loss: 0.0455\n",
      "Average validation loss: 0.049335639813216405\n",
      "80/80 [==============================] - 344s 709ms/step - loss: 8.5042e-05 - val_loss: 0.0461\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 401s 708ms/step - loss: 8.4946e-05 - val_loss: 0.0461\n",
      "Average validation loss: 0.04362464011646807\n",
      "80/80 [==============================] - 402s 718ms/step - loss: 8.4946e-05 - val_loss: 0.0458\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 458s 709ms/step - loss: 8.3704e-05 - val_loss: 0.0458\n",
      "Average validation loss: 0.04458814361132681\n",
      "80/80 [==============================] - 459s 719ms/step - loss: 8.3704e-05 - val_loss: 0.0456\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 516s 704ms/step - loss: 8.2511e-05 - val_loss: 0.0456\n",
      "Average validation loss: 0.035851757926866415\n",
      "80/80 [==============================] - 516s 714ms/step - loss: 8.2511e-05 - val_loss: 0.0445\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 572s 700ms/step - loss: 8.1788e-05 - val_loss: 0.0445\n",
      "Average validation loss: 0.03648591823875904\n",
      "80/80 [==============================] - 573s 710ms/step - loss: 8.1788e-05 - val_loss: 0.0437\n",
      "Train loss: 8.178778005015985e-05, Validation loss: 0.043725124814664014\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "  1/160 [..............................] - ETA: 1:51 - loss: 5.4892e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 112s 701ms/step - loss: 7.7884e-05\n",
      "Average validation loss: 0.03296219476033002\n",
      "160/160 [==============================] - 114s 711ms/step - loss: 7.7884e-05 - val_loss: 0.0330\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 226s 701ms/step - loss: 8.0461e-05 - val_loss: 0.0330\n",
      "Average validation loss: 0.04090976212755777\n",
      "160/160 [==============================] - 228s 711ms/step - loss: 8.0461e-05 - val_loss: 0.0369\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 341s 708ms/step - loss: 7.8871e-05 - val_loss: 0.0369\n",
      "Average validation loss: 0.08337172298051883\n",
      "160/160 [==============================] - 343s 718ms/step - loss: 7.8871e-05 - val_loss: 0.0524\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 456s 710ms/step - loss: 7.7532e-05 - val_loss: 0.0524\n",
      "Average validation loss: 0.034960704226978126\n",
      "160/160 [==============================] - 458s 720ms/step - loss: 7.7532e-05 - val_loss: 0.0481\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 570s 700ms/step - loss: 7.7011e-05 - val_loss: 0.0481\n",
      "Average validation loss: 0.06250501878093928\n",
      "160/160 [==============================] - 571s 710ms/step - loss: 7.7011e-05 - val_loss: 0.0509\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 684s 702ms/step - loss: 7.7309e-05 - val_loss: 0.0509\n",
      "Average validation loss: 0.04299815709237009\n",
      "160/160 [==============================] - 685s 712ms/step - loss: 7.7309e-05 - val_loss: 0.0496\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 799s 711ms/step - loss: 7.6766e-05 - val_loss: 0.0496\n",
      "Average validation loss: 0.056080774613656105\n",
      "160/160 [==============================] - 801s 721ms/step - loss: 7.6766e-05 - val_loss: 0.0505\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 914s 709ms/step - loss: 7.6203e-05 - val_loss: 0.0505\n",
      "Average validation loss: 0.06192002533935011\n",
      "160/160 [==============================] - 916s 719ms/step - loss: 7.6203e-05 - val_loss: 0.0520\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1032s 723ms/step - loss: 7.5108e-05 - val_loss: 0.0520\n",
      "Average validation loss: 0.03472464777296409\n",
      "160/160 [==============================] - 1033s 734ms/step - loss: 7.5108e-05 - val_loss: 0.0500\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1160s 788ms/step - loss: 7.4273e-05 - val_loss: 0.0500\n",
      "Average validation loss: 0.03916755515674595\n",
      "160/160 [==============================] - 1161s 799ms/step - loss: 7.4273e-05 - val_loss: 0.0490\n",
      "Train loss: 7.42725317866881e-05, Validation loss: 0.04896005628514104\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 126s 787ms/step - loss: 7.5385e-05\n",
      "Average validation loss: 0.05092777763493359\n",
      "160/160 [==============================] - 128s 798ms/step - loss: 7.5385e-05 - val_loss: 0.0509\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 255s 794ms/step - loss: 7.3502e-05 - val_loss: 0.0509\n",
      "Average validation loss: 0.030800833273679017\n",
      "160/160 [==============================] - 256s 805ms/step - loss: 7.3502e-05 - val_loss: 0.0409\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 383s 791ms/step - loss: 7.5308e-05 - val_loss: 0.0409\n",
      "Average validation loss: 0.03351556995185092\n",
      "160/160 [==============================] - 385s 802ms/step - loss: 7.5308e-05 - val_loss: 0.0384\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 511s 785ms/step - loss: 7.4587e-05 - val_loss: 0.0384\n",
      "Average validation loss: 0.042089600302279\n",
      "160/160 [==============================] - 512s 796ms/step - loss: 7.4587e-05 - val_loss: 0.0393\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 638s 785ms/step - loss: 7.3657e-05 - val_loss: 0.0393\n",
      "Average validation loss: 0.029839500249363483\n",
      "160/160 [==============================] - 640s 796ms/step - loss: 7.3657e-05 - val_loss: 0.0374\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 766s 787ms/step - loss: 7.3320e-05 - val_loss: 0.0374\n",
      "Average validation loss: 0.05306917988928035\n",
      "160/160 [==============================] - 767s 798ms/step - loss: 7.3320e-05 - val_loss: 0.0400\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 894s 787ms/step - loss: 7.2373e-05 - val_loss: 0.0400\n",
      "Average validation loss: 0.045186799089424315\n",
      "160/160 [==============================] - 895s 798ms/step - loss: 7.2373e-05 - val_loss: 0.0408\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1021s 788ms/step - loss: 7.1315e-05 - val_loss: 0.0408\n",
      "Average validation loss: 0.03125621462240815\n",
      "160/160 [==============================] - 1023s 799ms/step - loss: 7.1315e-05 - val_loss: 0.0396\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1149s 788ms/step - loss: 7.0890e-05 - val_loss: 0.0396\n",
      "Average validation loss: 0.03164033766370267\n",
      "160/160 [==============================] - 1151s 799ms/step - loss: 7.0890e-05 - val_loss: 0.0387\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1277s 786ms/step - loss: 6.9850e-05 - val_loss: 0.0387\n",
      "Average validation loss: 0.029533060221001505\n",
      "160/160 [==============================] - 1279s 797ms/step - loss: 6.9850e-05 - val_loss: 0.0378\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Train loss: 6.985010945620527e-05, Validation loss: 0.0377858872897923\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 126s 789ms/step - loss: 6.7230e-05\n",
      "Average validation loss: 0.030919930106028913\n",
      "160/160 [==============================] - 128s 800ms/step - loss: 6.7230e-05 - val_loss: 0.0309\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 254s 788ms/step - loss: 6.2350e-05 - val_loss: 0.0309\n",
      "Average validation loss: 0.03333012645598501\n",
      "160/160 [==============================] - 256s 799ms/step - loss: 6.2350e-05 - val_loss: 0.0321\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 382s 786ms/step - loss: 5.9182e-05 - val_loss: 0.0321\n",
      "Average validation loss: 0.03060921815922484\n",
      "160/160 [==============================] - 384s 797ms/step - loss: 5.9182e-05 - val_loss: 0.0316\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 510s 791ms/step - loss: 5.7165e-05 - val_loss: 0.0316\n",
      "Average validation loss: 0.080382463146816\n",
      "160/160 [==============================] - 512s 802ms/step - loss: 5.7165e-05 - val_loss: 0.0438\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 639s 794ms/step - loss: 5.5561e-05 - val_loss: 0.0438\n",
      "Average validation loss: 0.02719044769182801\n",
      "160/160 [==============================] - 641s 805ms/step - loss: 5.5561e-05 - val_loss: 0.0405\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 768s 792ms/step - loss: 5.4874e-05 - val_loss: 0.0405\n",
      "Average validation loss: 0.03815419593593106\n",
      "160/160 [==============================] - 770s 803ms/step - loss: 5.4874e-05 - val_loss: 0.0401\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 896s 789ms/step - loss: 5.4970e-05 - val_loss: 0.0401\n",
      "Average validation loss: 0.0294350249459967\n",
      "160/160 [==============================] - 897s 799ms/step - loss: 5.4970e-05 - val_loss: 0.0386\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1023s 787ms/step - loss: 5.2933e-05 - val_loss: 0.0386\n",
      "Average validation loss: 0.04159468906000256\n",
      "160/160 [==============================] - 1025s 798ms/step - loss: 5.2933e-05 - val_loss: 0.0390\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1151s 790ms/step - loss: 5.1290e-05 - val_loss: 0.0390\n",
      "Average validation loss: 0.024781069089658558\n",
      "160/160 [==============================] - 1153s 801ms/step - loss: 5.1290e-05 - val_loss: 0.0374\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1279s 788ms/step - loss: 5.0029e-05 - val_loss: 0.0374\n",
      "Average validation loss: 0.02523580491542816\n",
      "160/160 [==============================] - 1281s 799ms/step - loss: 5.0029e-05 - val_loss: 0.0362\n",
      "Train loss: 5.002905297174184e-05, Validation loss: 0.036163296950689976\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 127s 793ms/step - loss: 4.1131e-05\n",
      "Average validation loss: 0.02517470780876465\n",
      "160/160 [==============================] - 129s 804ms/step - loss: 4.1131e-05 - val_loss: 0.0252\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 256s 794ms/step - loss: 3.8423e-05 - val_loss: 0.0252\n",
      "Average validation loss: 0.0227594417243381\n",
      "160/160 [==============================] - 257s 805ms/step - loss: 3.8423e-05 - val_loss: 0.0240\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 384s 794ms/step - loss: 3.8414e-05 - val_loss: 0.0240\n",
      "Average validation loss: 0.02852455789980013\n",
      "160/160 [==============================] - 386s 804ms/step - loss: 3.8414e-05 - val_loss: 0.0255\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 514s 796ms/step - loss: 4.0166e-05 - val_loss: 0.0255\n",
      "Average validation loss: 0.14397425539791583\n",
      "160/160 [==============================] - 515s 807ms/step - loss: 4.0166e-05 - val_loss: 0.0551\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 642s 792ms/step - loss: 4.2049e-05 - val_loss: 0.0551\n",
      "Average validation loss: 0.025136856781318783\n",
      "160/160 [==============================] - 644s 803ms/step - loss: 4.2049e-05 - val_loss: 0.0491\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 771s 793ms/step - loss: 4.2153e-05 - val_loss: 0.0491\n",
      "Average validation loss: 0.02520424148242455\n",
      "160/160 [==============================] - 772s 804ms/step - loss: 4.2153e-05 - val_loss: 0.0451\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 899s 791ms/step - loss: 4.0180e-05 - val_loss: 0.0451\n",
      "Average validation loss: 0.02466499636066146\n",
      "160/160 [==============================] - 901s 802ms/step - loss: 4.0180e-05 - val_loss: 0.0422\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1027s 792ms/step - loss: 3.8360e-05 - val_loss: 0.0422\n",
      "Average validation loss: 0.022339269942312966\n",
      "160/160 [==============================] - 1029s 803ms/step - loss: 3.8360e-05 - val_loss: 0.0397\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1157s 798ms/step - loss: 3.8298e-05 - val_loss: 0.0397\n",
      "Average validation loss: 0.02813029603275936\n",
      "160/160 [==============================] - 1159s 809ms/step - loss: 3.8298e-05 - val_loss: 0.0384\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1285s 791ms/step - loss: 3.7706e-05 - val_loss: 0.0384\n",
      "Average validation loss: 0.024075643750256857\n",
      "160/160 [==============================] - 1287s 802ms/step - loss: 3.7706e-05 - val_loss: 0.0370\n",
      "Train loss: 3.770607898642578e-05, Validation loss: 0.03699842671805527\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 127s 791ms/step - loss: 3.6223e-05\n",
      "Average validation loss: 0.021786055422853678\n",
      "160/160 [==============================] - 128s 802ms/step - loss: 3.6223e-05 - val_loss: 0.0218\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 255s 788ms/step - loss: 3.2392e-05 - val_loss: 0.0218\n",
      "Average validation loss: 0.019741295312996954\n",
      "160/160 [==============================] - 256s 799ms/step - loss: 3.2392e-05 - val_loss: 0.0208\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 383s 793ms/step - loss: 3.1593e-05 - val_loss: 0.0208\n",
      "Average validation loss: 0.017941853147931397\n",
      "160/160 [==============================] - 385s 804ms/step - loss: 3.1593e-05 - val_loss: 0.0198\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 512s 796ms/step - loss: 2.9644e-05 - val_loss: 0.0198\n",
      "Average validation loss: 0.016364722419530152\n",
      "160/160 [==============================] - 514s 807ms/step - loss: 2.9644e-05 - val_loss: 0.0190\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 641s 795ms/step - loss: 2.8874e-05 - val_loss: 0.0190\n",
      "Average validation loss: 0.015325140190543606\n",
      "160/160 [==============================] - 643s 806ms/step - loss: 2.8874e-05 - val_loss: 0.0182\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_200.pth'.\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 760s 731ms/step - loss: 2.8709e-05 - val_loss: 0.0182\n",
      "Average validation loss: 0.022437753994017838\n",
      "160/160 [==============================] - 762s 742ms/step - loss: 2.8709e-05 - val_loss: 0.0189\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 875s 705ms/step - loss: 2.8351e-05 - val_loss: 0.0189\n",
      "Average validation loss: 0.02517360516358167\n",
      "160/160 [==============================] - 876s 715ms/step - loss: 2.8351e-05 - val_loss: 0.0198\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 989s 706ms/step - loss: 2.9155e-05 - val_loss: 0.0198\n",
      "Average validation loss: 0.022453609388321638\n",
      "160/160 [==============================] - 991s 717ms/step - loss: 2.9155e-05 - val_loss: 0.0202\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1104s 708ms/step - loss: 2.9127e-05 - val_loss: 0.0202\n",
      "Average validation loss: 0.025107125454815103\n",
      "160/160 [==============================] - 1106s 718ms/step - loss: 2.9127e-05 - val_loss: 0.0207\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1219s 705ms/step - loss: 2.9132e-05 - val_loss: 0.0207\n",
      "Average validation loss: 0.018025418452452868\n",
      "160/160 [==============================] - 1220s 714ms/step - loss: 2.9132e-05 - val_loss: 0.0204\n",
      "Train loss: 2.9132015947808556e-05, Validation loss: 0.02043565789470449\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/240 [..............................] - ETA: 2:42 - loss: 2.8550e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial01\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 171s 712ms/step - loss: 5.9232e-05\n",
      "Average validation loss: 0.03516278120999535\n",
      "240/240 [==============================] - 173s 722ms/step - loss: 5.9232e-05 - val_loss: 0.0352\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 344s 711ms/step - loss: 5.0943e-05 - val_loss: 0.0352\n",
      "Average validation loss: 0.028942811062249045\n",
      "240/240 [==============================] - 346s 721ms/step - loss: 5.0943e-05 - val_loss: 0.0321\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 517s 710ms/step - loss: 4.7561e-05 - val_loss: 0.0321\n",
      "Average validation loss: 0.03029778685498362\n",
      "240/240 [==============================] - 519s 720ms/step - loss: 4.7561e-05 - val_loss: 0.0315\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 690s 713ms/step - loss: 4.3646e-05 - val_loss: 0.0315\n",
      "Average validation loss: 0.03596885095660885\n",
      "240/240 [==============================] - 693s 723ms/step - loss: 4.3646e-05 - val_loss: 0.0326\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 864s 712ms/step - loss: 4.2205e-05 - val_loss: 0.0326\n",
      "Average validation loss: 0.02739049829930688\n",
      "240/240 [==============================] - 866s 722ms/step - loss: 4.2205e-05 - val_loss: 0.0316\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1036s 707ms/step - loss: 3.9422e-05 - val_loss: 0.0316\n",
      "Average validation loss: 0.025210287239557753\n",
      "240/240 [==============================] - 1038s 717ms/step - loss: 3.9422e-05 - val_loss: 0.0305\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1208s 707ms/step - loss: 3.8070e-05 - val_loss: 0.0305\n",
      "Average validation loss: 0.029164224420674144\n",
      "240/240 [==============================] - 1210s 717ms/step - loss: 3.8070e-05 - val_loss: 0.0303\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1380s 707ms/step - loss: 3.7724e-05 - val_loss: 0.0303\n",
      "Average validation loss: 0.023817661652962365\n",
      "240/240 [==============================] - 1382s 716ms/step - loss: 3.7724e-05 - val_loss: 0.0295\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1552s 709ms/step - loss: 3.6676e-05 - val_loss: 0.0295\n",
      "Average validation loss: 0.024885101387432464\n",
      "240/240 [==============================] - 1555s 719ms/step - loss: 3.6676e-05 - val_loss: 0.0290\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1725s 710ms/step - loss: 3.5668e-05 - val_loss: 0.0290\n",
      "Average validation loss: 0.024360000021988525\n",
      "240/240 [==============================] - 1727s 720ms/step - loss: 3.5668e-05 - val_loss: 0.0285\n",
      "Train loss: 3.566766779179309e-05, Validation loss: 0.028520000310575895\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 170s 707ms/step - loss: 4.2632e-05\n",
      "Average validation loss: 0.01964135808714976\n",
      "240/240 [==============================] - 172s 717ms/step - loss: 4.2632e-05 - val_loss: 0.0196\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 343s 710ms/step - loss: 3.8558e-05 - val_loss: 0.0196\n",
      "Average validation loss: 0.019467892850904413\n",
      "240/240 [==============================] - 345s 720ms/step - loss: 3.8558e-05 - val_loss: 0.0196\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 514s 705ms/step - loss: 3.4695e-05 - val_loss: 0.0196\n",
      "Average validation loss: 0.019098332824069076\n",
      "240/240 [==============================] - 516s 715ms/step - loss: 3.4695e-05 - val_loss: 0.0194\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 686s 707ms/step - loss: 3.3404e-05 - val_loss: 0.0194\n",
      "Average validation loss: 0.01854590051322399\n",
      "240/240 [==============================] - 689s 717ms/step - loss: 3.3404e-05 - val_loss: 0.0192\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 859s 707ms/step - loss: 3.0963e-05 - val_loss: 0.0192\n",
      "Average validation loss: 0.01604125974942387\n",
      "240/240 [==============================] - 861s 717ms/step - loss: 3.0963e-05 - val_loss: 0.0186\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1031s 709ms/step - loss: 2.9700e-05 - val_loss: 0.0186\n",
      "Average validation loss: 0.01732979338072861\n",
      "240/240 [==============================] - 1033s 719ms/step - loss: 2.9700e-05 - val_loss: 0.0184\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1205s 713ms/step - loss: 2.9774e-05 - val_loss: 0.0184\n",
      "Average validation loss: 0.05302479242285093\n",
      "240/240 [==============================] - 1207s 723ms/step - loss: 2.9774e-05 - val_loss: 0.0233\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1377s 708ms/step - loss: 3.0886e-05 - val_loss: 0.0233\n",
      "Average validation loss: 0.022239384766726288\n",
      "240/240 [==============================] - 1379s 718ms/step - loss: 3.0886e-05 - val_loss: 0.0232\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1549s 705ms/step - loss: 3.0227e-05 - val_loss: 0.0232\n",
      "Average validation loss: 0.0201668130151423\n",
      "240/240 [==============================] - 1551s 715ms/step - loss: 3.0227e-05 - val_loss: 0.0228\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1720s 704ms/step - loss: 3.0851e-05 - val_loss: 0.0228\n",
      "Average validation loss: 0.027291411237092687\n",
      "240/240 [==============================] - 1722s 714ms/step - loss: 3.0851e-05 - val_loss: 0.0233\n",
      "Train loss: 3.0851306487274856e-05, Validation loss: 0.023284693884731193\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 171s 712ms/step - loss: 2.9936e-05\n",
      "Average validation loss: 0.018979140138738634\n",
      "240/240 [==============================] - 173s 722ms/step - loss: 2.9936e-05 - val_loss: 0.0190\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 344s 713ms/step - loss: 3.0122e-05 - val_loss: 0.0190\n",
      "Average validation loss: 0.017036782352564235\n",
      "240/240 [==============================] - 347s 723ms/step - loss: 3.0122e-05 - val_loss: 0.0180\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 516s 707ms/step - loss: 2.6636e-05 - val_loss: 0.0180\n",
      "Average validation loss: 0.017666023854205074\n",
      "240/240 [==============================] - 519s 717ms/step - loss: 2.6636e-05 - val_loss: 0.0179\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 688s 705ms/step - loss: 2.6625e-05 - val_loss: 0.0179\n",
      "Average validation loss: 0.015889197254242995\n",
      "240/240 [==============================] - 690s 715ms/step - loss: 2.6625e-05 - val_loss: 0.0174\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 860s 708ms/step - loss: 2.7115e-05 - val_loss: 0.0174\n",
      "Average validation loss: 0.019588993307358273\n",
      "240/240 [==============================] - 863s 717ms/step - loss: 2.7115e-05 - val_loss: 0.0178\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1033s 711ms/step - loss: 2.6384e-05 - val_loss: 0.0178\n",
      "Average validation loss: 0.028901911060286996\n",
      "240/240 [==============================] - 1036s 721ms/step - loss: 2.6384e-05 - val_loss: 0.0197\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1205s 707ms/step - loss: 2.9274e-05 - val_loss: 0.0197\n",
      "Average validation loss: 0.0264673140947707\n",
      "240/240 [==============================] - 1208s 717ms/step - loss: 2.9274e-05 - val_loss: 0.0206\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1378s 709ms/step - loss: 2.8674e-05 - val_loss: 0.0206\n",
      "Average validation loss: 0.021656307527640212\n",
      "240/240 [==============================] - 1380s 719ms/step - loss: 2.8674e-05 - val_loss: 0.0208\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1551s 709ms/step - loss: 2.7612e-05 - val_loss: 0.0208\n",
      "Average validation loss: 0.023279444376627604\n",
      "240/240 [==============================] - 1553s 719ms/step - loss: 2.7612e-05 - val_loss: 0.0211\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1723s 706ms/step - loss: 2.7114e-05 - val_loss: 0.0211\n",
      "Average validation loss: 0.01880889560173576\n",
      "240/240 [==============================] - 1725s 716ms/step - loss: 2.7114e-05 - val_loss: 0.0208\n",
      "Train loss: 2.711388971441362e-05, Validation loss: 0.02082740095681705\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 169s 705ms/step - loss: 2.4043e-05\n",
      "Average validation loss: 0.022068560837457576\n",
      "240/240 [==============================] - 172s 715ms/step - loss: 2.4043e-05 - val_loss: 0.0221\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 341s 707ms/step - loss: 2.4486e-05 - val_loss: 0.0221\n",
      "Average validation loss: 0.019102641554006063\n",
      "240/240 [==============================] - 344s 717ms/step - loss: 2.4486e-05 - val_loss: 0.0206\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 513s 705ms/step - loss: 2.3206e-05 - val_loss: 0.0206\n",
      "Average validation loss: 0.014043729473875525\n",
      "240/240 [==============================] - 515s 715ms/step - loss: 2.3206e-05 - val_loss: 0.0184\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 685s 708ms/step - loss: 2.1683e-05 - val_loss: 0.0184\n",
      "Average validation loss: 0.01433496324752923\n",
      "240/240 [==============================] - 688s 718ms/step - loss: 2.1683e-05 - val_loss: 0.0174\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 857s 706ms/step - loss: 2.4043e-05 - val_loss: 0.0174\n",
      "Average validation loss: 0.017790182796306907\n",
      "240/240 [==============================] - 860s 716ms/step - loss: 2.4043e-05 - val_loss: 0.0175\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1033s 724ms/step - loss: 2.3233e-05 - val_loss: 0.0175\n",
      "Average validation loss: 0.01476862768564994\n",
      "240/240 [==============================] - 1036s 734ms/step - loss: 2.3233e-05 - val_loss: 0.0170\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1206s 707ms/step - loss: 2.2007e-05 - val_loss: 0.0170\n",
      "Average validation loss: 0.014941061894448163\n",
      "240/240 [==============================] - 1208s 717ms/step - loss: 2.2007e-05 - val_loss: 0.0167\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1378s 709ms/step - loss: 2.1204e-05 - val_loss: 0.0167\n",
      "Average validation loss: 0.022527473032823764\n",
      "240/240 [==============================] - 1380s 718ms/step - loss: 2.1204e-05 - val_loss: 0.0174\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1563s 759ms/step - loss: 2.0680e-05 - val_loss: 0.0174\n",
      "Average validation loss: 0.01947796601743903\n",
      "240/240 [==============================] - 1565s 769ms/step - loss: 2.0680e-05 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1750s 769ms/step - loss: 1.9959e-05 - val_loss: 0.0177\n",
      "Average validation loss: 0.01691231732062685\n",
      "240/240 [==============================] - 1753s 780ms/step - loss: 1.9959e-05 - val_loss: 0.0176\n",
      "Train loss: 1.9958650249016403e-05, Validation loss: 0.017596752386016306\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 170s 709ms/step - loss: 2.0671e-05\n",
      "Average validation loss: 0.01858418102104527\n",
      "240/240 [==============================] - 172s 719ms/step - loss: 2.0671e-05 - val_loss: 0.0186\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 342s 705ms/step - loss: 2.4364e-05 - val_loss: 0.0186\n",
      "Average validation loss: 0.017478824922970187\n",
      "240/240 [==============================] - 344s 714ms/step - loss: 2.4364e-05 - val_loss: 0.0180\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 513s 705ms/step - loss: 2.3614e-05 - val_loss: 0.0180\n",
      "Average validation loss: 0.012283346516778693\n",
      "240/240 [==============================] - 516s 715ms/step - loss: 2.3614e-05 - val_loss: 0.0161\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30\\segformer_data_size_300.pth'.\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 685s 707ms/step - loss: 2.2664e-05 - val_loss: 0.0161\n",
      "Average validation loss: 0.015795678408661237\n",
      "240/240 [==============================] - 688s 716ms/step - loss: 2.2664e-05 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 858s 710ms/step - loss: 2.8618e-05 - val_loss: 0.0160\n",
      "Average validation loss: 0.018974454728110383\n",
      "240/240 [==============================] - 860s 720ms/step - loss: 2.8618e-05 - val_loss: 0.0166\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1030s 706ms/step - loss: 2.8195e-05 - val_loss: 0.0166\n",
      "Average validation loss: 0.015058187942486256\n",
      "240/240 [==============================] - 1032s 716ms/step - loss: 2.8195e-05 - val_loss: 0.0164\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1202s 706ms/step - loss: 3.0552e-05 - val_loss: 0.0164\n",
      "Average validation loss: 0.018984796619042753\n",
      "240/240 [==============================] - 1204s 716ms/step - loss: 3.0552e-05 - val_loss: 0.0167\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1374s 708ms/step - loss: 2.9909e-05 - val_loss: 0.0167\n",
      "Average validation loss: 0.02966223356682652\n",
      "240/240 [==============================] - 1376s 717ms/step - loss: 2.9909e-05 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1546s 707ms/step - loss: 2.8596e-05 - val_loss: 0.0184\n",
      "Average validation loss: 0.01656582742774238\n",
      "240/240 [==============================] - 1548s 717ms/step - loss: 2.8596e-05 - val_loss: 0.0182\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1715s 694ms/step - loss: 2.7049e-05 - val_loss: 0.0182\n",
      "Average validation loss: 0.013649946016569933\n",
      "240/240 [==============================] - 1717s 703ms/step - loss: 2.7049e-05 - val_loss: 0.0177\n",
      "Train loss: 2.704910995375185e-05, Validation loss: 0.01770374771702336\n",
      "CPU times: total: 5h 48min 18s\n",
      "Wall time: 5h 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig, SegformerImageProcessor\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import SamModel, SamProcessor\n",
    "from torch import nn\n",
    "from scipy.ndimage import label, find_objects\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datetime import datetime\n",
    "\n",
    "# DataSet\n",
    "class SplashDataSet_train_val_0501(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.images_dir = os.path.join(self.root_dir, \"images\")\n",
    "        self.masks_dir = os.path.join(self.root_dir, \"annotations\")\n",
    "        # get filenames\n",
    "        self.images_list = sorted(os.listdir(self.images_dir))\n",
    "        self.masks_list = sorted(os.listdir(self.masks_dir))\n",
    "        assert len(self.images_list) == len(self.masks_list), \"Number of images and annotations should be the same.\"\n",
    "\n",
    "        # transform image to 1024*1024\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((1024, 1024)),\n",
    "            transforms.ToTensor(),  # This will scale pixel values to [0, 1]\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get image and annotation file\n",
    "        img_path = os.path.join(self.images_dir, self.images_list[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks_list[idx])\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        # Convert mask to binary 0 and 1\n",
    "        mask = (mask > 0).to(torch.int)\n",
    "        mask = mask[0, None, :, :]\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "    def get_time_category(self, filename):\n",
    "        # my filenames' format is 2024-04-09-03-00-11.png\n",
    "        time_str = filename.split('-')[3:5]\n",
    "        time_obj = datetime.strptime('-'.join(time_str), '%H-%M')\n",
    "        hour = time_obj.hour\n",
    "        if hour < 8:\n",
    "            return 'morning'\n",
    "        elif 8 <= hour <= 16:\n",
    "            return 'day'\n",
    "        else:\n",
    "            return 'evening'\n",
    "\n",
    "def focal_loss(inputs, targets, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "    #print(\"inputs size = \", inputs.size())\n",
    "    # inputs size =  torch.Size([1, 2, 1024, 1024])\n",
    "    #print(\"targets size = \", targets.size())\n",
    "    # targets size =  torch.Size([1, 1024, 1024])\n",
    "    BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "    targets = targets.type(torch.float32)\n",
    "    at = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "    pt = torch.exp(-BCE_loss)\n",
    "    F_loss = at * (1 - pt)**gamma * BCE_loss\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(F_loss), (1 - pt)**gamma\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(F_loss)\n",
    "    else:\n",
    "        return F_loss\n",
    "\n",
    "# criterion\n",
    "def criterion(outputs, labels):\n",
    "    return torch.nn.functional.cross_entropy(outputs, labels.squeeze(1).long())\n",
    "\n",
    "def KD_criterion(student_outputs, teacher_outputs, labels, teacher_ratio, temperature):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    #print(\"student_outputs size = \", student_outputs.size())\n",
    "    # print(\"student_outputs = \", student_outputs[\"out\"])\n",
    "    #print(\"teacher_outputs size = \", teacher_outputs.size())\n",
    "    # print(\"teacher_outputs = \", teacher_outputs)\n",
    "    #print(\"ground truth size = \", labels.size())\n",
    "    \n",
    "    # Calculate Cross Entropy\n",
    "    # original_loss = torch.nn.functional.cross_entropy(student_outputs, labels.squeeze(1).long())\n",
    "\n",
    "    # Calculate Focal Loss , not sure about alpha and gamme\n",
    "    #original_loss = focal_loss(student_outputs[:,1,:,:], labels.squeeze(1).float(), alpha=0.25, gamma=2.0)\n",
    "    alpha=0.25\n",
    "    gamma=2.0\n",
    "    targets = labels.squeeze(1).float()\n",
    "    BCE_loss = F.binary_cross_entropy_with_logits(student_outputs[:,1,:,:], targets, reduction='none')\n",
    "    targets = targets.type(torch.float32)\n",
    "    at = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "    pt = torch.exp(-BCE_loss)\n",
    "    modulating_number = torch.mean((1 - pt)**gamma)\n",
    "    F_loss = at * modulating_number * BCE_loss\n",
    "    #print(\"modulating_number = \", modulating_number)\n",
    "    # mean\n",
    "    original_loss = torch.mean(F_loss)\n",
    "    #print(\"original loss = \", original_loss)\n",
    "\n",
    "    # Calculate Distillation Loss\n",
    "    soft_teacher_outputs = torch.softmax(teacher_outputs[0, 0, :, :] / temperature, dim=1)\n",
    "    soft_student_outputs = torch.log_softmax(student_outputs[0, 0, :, :] / temperature, dim=1)\n",
    "    distillation_loss = nn.KLDivLoss()(soft_student_outputs.to(device), soft_teacher_outputs.to(device))\n",
    "    #print(\"distillation loss = \", distillation_loss)\n",
    "    \n",
    "    # total loss\n",
    "    #total_loss = modulating_number*((1-teacher_ratio)*original_loss + teacher_ratio*distillation_loss)\n",
    "    total_loss = (1-teacher_ratio)*original_loss + teacher_ratio*distillation_loss*modulating_number\n",
    "    return total_loss\n",
    "\n",
    "# evaluate\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for image, mask in val_loader:\n",
    "            image, mask = image.to(device), mask.to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "\n",
    "            loss = criterion(outputs['out'], mask)\n",
    "\n",
    "            # Calculate Focal Loss , not sure about alpha and gamme\n",
    "            #print(\"outputs size = \", outputs['out'].size())\n",
    "            #print(\"mask size = \", mask.size())\n",
    "            # outputs['out'] size =  torch.Size([1, 2, 1024, 1024])\n",
    "            # mask size =  torch.Size([1, 1, 1024, 1024])\n",
    "            #loss = focal_loss(outputs['out'][:,1:2,:,:], mask.float())\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    print(f\"Average validation loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "# train every epoch\n",
    "def train_one_epoch(student_model, teacher_model, teacher_image_processor, data_loader, teacher_ratio, temperature, optimizer, device, pbar):\n",
    "    student_model.to(device)\n",
    "    student_model.train()\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    training_loss = []\n",
    "    for idx, (image, mask) in enumerate(data_loader):\n",
    "        #bbox = [[[get_bounding_box(np.array(mask))]]]\n",
    "        bbox, point = get_bounding_box_and_center(np.array(mask))\n",
    "        #print(\"[train_one_epoch] bbox = \", bbox)\n",
    "        #print(\"[train_one_epoch] point = \", point)\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        # image size = torch.Size([1, 3, 1024, 1024])start_step\n",
    "        # mask size = torch.Size([1, 1, 1024, 1024])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # output for student model ----------------------------------------------------------\n",
    "        student_outputs = student_model(image)\n",
    "        # outputs size = torch.Size([1, 2, 1024, 1024])\n",
    "        # -----------------------------------------------------------------------------------\n",
    "        # output for teacher model ----------------------------------------------------------\n",
    "        # Retrieve the image embeddings\n",
    "        # processor\n",
    "        teacher_inputs = teacher_image_processor(image, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "        teacher_image_embeddings = teacher_model.get_image_embeddings(teacher_inputs[\"pixel_values\"])\n",
    "        \n",
    "        # 送到processor計算遮罩\n",
    "        if bbox is None:\n",
    "            teacher_inputs = teacher_image_processor(image, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "        else:\n",
    "            teacher_inputs = teacher_image_processor(image, input_points=[[[point]]], input_boxes=[[[bbox]]], return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "\n",
    "        teacher_inputs.pop(\"pixel_values\", None)\n",
    "        teacher_inputs.update({\"image_embeddings\": teacher_image_embeddings})\n",
    "\n",
    "        teacher_outputs = teacher_model(**teacher_inputs)\n",
    "        teacher_masks, teacher_output = teacher_image_processor.image_processor.post_process_masks(teacher_outputs.pred_masks.cpu(), teacher_inputs[\"original_sizes\"].cpu(), teacher_inputs[\"reshaped_input_sizes\"].cpu())  \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        #loss = criterion(student_outputs, mask)\n",
    "        loss = KD_criterion(student_outputs['out'], teacher_output[0], mask, teacher_ratio, temperature)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \"\"\"\n",
    "        [train_one_epoch] image size =  torch.Size([1, 3, 1024, 1024])\n",
    "        [train_one_epoch]0 mask size =  torch.Size([1, 1, 1024, 1024])\n",
    "        [train_one_epoch]0 outputs size =  torch.Size([1, 2, 128, 128])\n",
    "        [train_one_epoch]1 outputs size =  torch.Size([1, 2, 1024, 1024])\n",
    "        \"\"\"\n",
    "        training_loss.append(loss.item())\n",
    "        pbar.update(idx + 1, values=[(\"loss\", loss.item())])\n",
    "    return np.mean(np.array(training_loss))\n",
    "\n",
    "# train\n",
    "def train(model, teacher_model, teacher_image_processor, train_loader, val_loader, train_size, save_model, teacher_ratio=0.7, temperature=1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device, \":\",torch.cuda.get_device_name(0))\n",
    "\n",
    "    train_losses   = []\n",
    "    val_losses     = []\n",
    "    epochs = 10\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    n_batch = len(train_loader)\n",
    "    pbar = tf.keras.utils.Progbar(target=n_batch, stateful_metrics=None)\n",
    "    ######### weight\n",
    "    # 動態生成儲存模型權重的檔名，加入目前使用的資料集大小的數字\n",
    "    weight_filename = f\"segformer_data_size_{train_size}.pth\"\n",
    "    # 確定weights資料夾是否存在，如果不存在則新增它\n",
    "    #weights_dir = os.path.join(os.getcwd(),\"weights\")\n",
    "    weights_dir = os.path.join(os.getcwd(), f\"weights/weights_KD_segformer_0628/weights_KD_segformer_0628_{int(teacher_ratio*100)}\")\n",
    "    if not os.path.exists(weights_dir):\n",
    "        os.makedirs(weights_dir)\n",
    "    model_pathname = os.path.join(weights_dir, weight_filename)\n",
    "    ######### weight end\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, teacher_model, teacher_image_processor, train_loader, teacher_ratio, temperature, optimizer, device, pbar)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_loss = evaluate(model, val_loader, device)\n",
    "            val_losses.append(val_loss)\n",
    "            pbar.update(n_batch, values=[('val_loss', val_loss)])\n",
    "\n",
    "            if val_loss < best_val_loss and save_model:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), model_pathname)\n",
    "                print(f\"Saved model weights to '{model_pathname}'.\")\n",
    "    print(f\"Train loss: {np.mean(train_losses)}, Validation loss: {np.mean(val_losses)}\" if val_loader is not None else f\"Train loss: {np.mean(train_losses)}\")\n",
    "    return {'loss':train_losses, 'val_loss':val_losses}\n",
    "\n",
    "def select_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    parent_folder = filedialog.askdirectory(title=\"選擇資料夾\")\n",
    "    return parent_folder\n",
    "\n",
    "def get_bounding_box(ground_truth_map):\n",
    "  ground_truth_map = ground_truth_map[0, 0, :, :]\n",
    "  #print(\"ground_truth_map = \", ground_truth_map.shape)\n",
    "  # get bounding box from mask\n",
    "  y_indices, x_indices = np.where(ground_truth_map > 0)\n",
    "  x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "  y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "  # add perturbation to bounding box coordinates\n",
    "  H, W = ground_truth_map.shape\n",
    "  x_min = max(0, x_min - np.random.randint(0, 20))\n",
    "  x_max = min(W, x_max + np.random.randint(0, 20))\n",
    "  y_min = max(0, y_min - np.random.randint(0, 20))\n",
    "  y_max = min(H, y_max + np.random.randint(0, 20))\n",
    "  bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "  return bbox\n",
    "\n",
    "def get_bounding_box_and_center(ground_truth_map):\n",
    "    #print(\"[get_bounding_box_and_center]\")\n",
    "    ground_truth_map = ground_truth_map[0, 0, :, :]\n",
    "    if np.any(ground_truth_map > 0):\n",
    "        # get bounding box from mask\n",
    "        y_indices, x_indices = np.where(ground_truth_map > 0)\n",
    "        x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "        y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "        # add perturbation to bounding box coordinates\n",
    "        H, W = ground_truth_map.shape\n",
    "        x_min = max(0, x_min - np.random.randint(0, 20))\n",
    "        x_max = min(W, x_max + np.random.randint(0, 20))\n",
    "        y_min = max(0, y_min - np.random.randint(0, 20))\n",
    "        y_max = min(H, y_max + np.random.randint(0, 20))\n",
    "        bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "        # Identify the largest connected component (largest mask area)\n",
    "        labeled_array, num_features = label(ground_truth_map > 0)\n",
    "        if num_features > 0:\n",
    "            # Find the largest component\n",
    "            max_label = 1 + np.argmax([np.sum(labeled_array == i) for i in range(1, num_features+1)])\n",
    "            # Get the slice for the largest component\n",
    "            largest_component_slice = find_objects(labeled_array == max_label)[0]\n",
    "            yc, xc = largest_component_slice\n",
    "            center_x = xc.start + (xc.stop - xc.start) // 2\n",
    "            center_y = yc.start + (yc.stop - yc.start) // 2\n",
    "            center_point = (center_x, center_y)\n",
    "        else:\n",
    "            center_point = ((x_min + x_max) // 2, (y_min + y_max) // 2)\n",
    "    else:\n",
    "        bbox = None\n",
    "        center_point = None\n",
    "    return bbox, center_point\n",
    "\n",
    "class MySegFormer_0628(nn.Module):\n",
    "    def __init__(self,num_classes,backbone=\"b0\",id2label=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if id2label is not None:\n",
    "            self.id2label = id2label\n",
    "        else:\n",
    "            self.id2label = {i:str(i) for i in range(self.num_classes)}\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(f\"nvidia/mit-{backbone}\",\n",
    "                                                         num_labels=self.num_classes, \n",
    "                                                         id2label=self.id2label, \n",
    "                                                         label2id={v:k for k,v in self.id2label.items()}\n",
    "                                                         , ignore_mismatched_sizes=True)\n",
    "    def forward(self,x):\n",
    "        y = self.segformer(x)\n",
    "        y = nn.functional.interpolate(y.logits, size=x.shape[-2:], mode=\"bilinear\", align_corners=False,antialias=True)        \n",
    "        return {'out':y}\n",
    "        # 在conda 環境裡huggingface包好的Segformer有改(modeling_segformer.py)\n",
    "\n",
    "# Student Model: Segformer 0601\n",
    "backbone = \"b0\"\n",
    "num_classes = 2\n",
    "model_segformer = MySegFormer_0628(num_classes, backbone)\n",
    "\n",
    "# Teacher Model: Segment Anything Model\n",
    "model_sam = SamModel.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "processor_sam = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "\n",
    "train_sizes = [5, 10, 100, 200, 300]\n",
    "#train_sizes = [300]\n",
    "# 放所有 fold 的 平均、標準差\n",
    "mean_val_losses = []\n",
    "std_val_losses = []\n",
    "root_dir = select_folder()\n",
    "\n",
    "#root_dir = \"C:/Users/user/Desktop/NAS_data/鱸魚/高雄黃明和/train_0418\"\n",
    "#print(root_dir)\n",
    "\n",
    "# My DataSet, return image, mask\n",
    "train_val_dataset = SplashDataSet_train_val_0501(root_dir=root_dir)\n",
    "labels = [train_val_dataset.get_time_category(filename) for filename in train_val_dataset.images_list]\n",
    "#print(\"indices 1= \", indices)\n",
    "#print(\"label size = \", label.size())\n",
    "#print(\"label = \", len(labels))\n",
    "#print(\"len(train_val_dataset = )\", len(train_val_dataset))\n",
    "for train_size in train_sizes:\n",
    "    # 在前一個大小的資料袋中擴增資料(train+validation)\n",
    "    indices = np.arange(len(train_val_dataset))\n",
    "    indices = indices[:train_size]\n",
    "    # print(\"indices = \", indices)\n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    val_losses = []  # 放每個 fold 的 validation loss\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(indices, [labels[i] for i in indices])):\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "        train_idx = indices[train_idx]\n",
    "        val_idx = indices[val_idx]\n",
    "        \"\"\"\n",
    "        for i in indices:\n",
    "            print(\"i = \", i)\n",
    "            print(\"labels[i] = \", labels[i])\n",
    "        print(\"----\")\n",
    "        \"\"\"\n",
    "        \n",
    "        train_subset = Subset(train_val_dataset, train_idx)\n",
    "        val_subset = Subset(train_val_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=1, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=1, shuffle=False)\n",
    "        # train\n",
    "        # Please replace Diatillation_Loss_Ratio to the teacher_ratio from 0 ~ 1 \n",
    "        teacher_ratio = 0.3\n",
    "        temperature = 5\n",
    "        lc = train(model_segformer, model_sam, processor_sam, train_loader, val_loader, train_size, True, teacher_ratio, temperature)\n",
    "\n",
    "        val_loss = lc['val_loss']\n",
    "        val_losses.append(val_loss)\n",
    "    mean_val_losses.append(np.mean(val_losses))\n",
    "    std_val_losses.append(np.std(val_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size size =  5\n",
      "mean_val_losses size =  5\n",
      "std_val_losses size =  5\n",
      "train_size =  [5, 10, 100, 200, 300]\n",
      "mean_val_losses =  [0.12153904214064823, 0.07827182524701623, 0.06823563545502838, 0.03606866502767661, 0.021586519051032767]\n",
      "std_val_losses =  [0.17194883975869724, 0.07916264330262077, 0.07266541541642797, 0.021274067293573947, 0.007093438218806451]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "print(\"train_size size = \", np.array(train_sizes).size)\n",
    "print(\"mean_val_losses size = \", np.array(mean_val_losses).size)\n",
    "print(\"std_val_losses size = \", np.array(std_val_losses).size)\n",
    "print(\"train_size = \", train_sizes)\n",
    "print(\"mean_val_losses = \", mean_val_losses)\n",
    "print(\"std_val_losses = \", std_val_losses)\n",
    "\n",
    "results_dir = os.path.join(os.getcwd(), 'TrainingRecords', 'results_KD_segformer_0628')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "results = {\n",
    "    \"train_sizes\": train_sizes,\n",
    "    \"mean_val_losses\": mean_val_losses,\n",
    "    \"std_val_losses\": std_val_losses\n",
    "}\n",
    "json_path = os.path.join(results_dir, f\"results_KD_segformer_0628_{int(teacher_ratio*100)}.json\")\n",
    "with open(json_path, 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, mean_val_losses, marker='o', color='black', label=f'distillation_loss_ratio={teacher_ratio}, original_loss_ratio={round(1-teacher_ratio, 2)}')\n",
    "plt.fill_between(train_sizes, np.maximum(0, np.array(mean_val_losses) - np.array(std_val_losses)), \n",
    "                 np.array(mean_val_losses) + np.array(std_val_losses), color='black', alpha=0.3)\n",
    "plt.title('Segformer B0')\n",
    "plt.xlabel('Dataset Size')\n",
    "plt.ylabel('Cross_Entropy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(results_dir, f\"results_KD_segformer_0628_{int(teacher_ratio*100)}.png\"))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam_trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
