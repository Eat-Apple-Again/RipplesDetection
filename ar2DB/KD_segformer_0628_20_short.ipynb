{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Position_Embedding_0628_teacher_0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 609ms/step - loss: 0.1000\n",
      "Average validation loss: 0.6837379932403564\n",
      "4/4 [==============================] - 5s 620ms/step - loss: 0.1000 - val_loss: 0.6837\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 8s 600ms/step - loss: 0.0709 - val_loss: 0.6837\n",
      "Average validation loss: 0.5770170092582703\n",
      "4/4 [==============================] - 8s 613ms/step - loss: 0.0709 - val_loss: 0.6304\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 10s 656ms/step - loss: 0.0540 - val_loss: 0.6304\n",
      "Average validation loss: 0.5100351572036743\n",
      "4/4 [==============================] - 10s 668ms/step - loss: 0.0540 - val_loss: 0.5903\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 13s 611ms/step - loss: 0.0433 - val_loss: 0.5903\n",
      "Average validation loss: 0.491826593875885\n",
      "4/4 [==============================] - 13s 624ms/step - loss: 0.0433 - val_loss: 0.5657\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 15s 678ms/step - loss: 0.0359 - val_loss: 0.5657\n",
      "Average validation loss: 0.3497009575366974\n",
      "4/4 [==============================] - 15s 691ms/step - loss: 0.0359 - val_loss: 0.5225\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 18s 684ms/step - loss: 0.0306 - val_loss: 0.5225\n",
      "Average validation loss: 0.2743995189666748\n",
      "4/4 [==============================] - 18s 694ms/step - loss: 0.0306 - val_loss: 0.4811\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 21s 780ms/step - loss: 0.0266 - val_loss: 0.4811\n",
      "Average validation loss: 0.26293259859085083\n",
      "4/4 [==============================] - 21s 798ms/step - loss: 0.0266 - val_loss: 0.4499\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 24s 771ms/step - loss: 0.0235 - val_loss: 0.4499\n",
      "Average validation loss: 0.22171913087368011\n",
      "4/4 [==============================] - 25s 787ms/step - loss: 0.0235 - val_loss: 0.4214\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 28s 758ms/step - loss: 0.0210 - val_loss: 0.4214\n",
      "Average validation loss: 0.15558911859989166\n",
      "4/4 [==============================] - 28s 773ms/step - loss: 0.0210 - val_loss: 0.3919\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 31s 775ms/step - loss: 0.0190 - val_loss: 0.3919\n",
      "Average validation loss: 0.15907034277915955\n",
      "4/4 [==============================] - 31s 794ms/step - loss: 0.0190 - val_loss: 0.3686\n",
      "Train loss: 0.019040713072172366, Validation loss: 0.36860284209251404\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0041\n",
      "Average validation loss: 0.13869121670722961\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.0041 - val_loss: 0.1387\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 775ms/step - loss: 0.0025 - val_loss: 0.1387\n",
      "Average validation loss: 0.09522013366222382\n",
      "4/4 [==============================] - 6s 792ms/step - loss: 0.0025 - val_loss: 0.1170\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 9s 778ms/step - loss: 0.0018 - val_loss: 0.1170\n",
      "Average validation loss: 0.017430873587727547\n",
      "4/4 [==============================] - 9s 791ms/step - loss: 0.0018 - val_loss: 0.0838\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 13s 782ms/step - loss: 0.0014 - val_loss: 0.0838\n",
      "Average validation loss: 0.009946167469024658\n",
      "4/4 [==============================] - 13s 800ms/step - loss: 0.0014 - val_loss: 0.0653\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 16s 769ms/step - loss: 0.0011 - val_loss: 0.0653\n",
      "Average validation loss: 0.011561490595340729\n",
      "4/4 [==============================] - 16s 783ms/step - loss: 0.0011 - val_loss: 0.0546\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 19s 778ms/step - loss: 9.4970e-04 - val_loss: 0.0546\n",
      "Average validation loss: 0.014088492840528488\n",
      "4/4 [==============================] - 19s 791ms/step - loss: 9.4970e-04 - val_loss: 0.0478\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 22s 774ms/step - loss: 8.2436e-04 - val_loss: 0.0478\n",
      "Average validation loss: 0.01931753382086754\n",
      "4/4 [==============================] - 22s 786ms/step - loss: 8.2436e-04 - val_loss: 0.0438\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 25s 786ms/step - loss: 7.2721e-04 - val_loss: 0.0438\n",
      "Average validation loss: 0.002614980563521385\n",
      "4/4 [==============================] - 25s 801ms/step - loss: 7.2721e-04 - val_loss: 0.0386\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 29s 795ms/step - loss: 6.5115e-04 - val_loss: 0.0386\n",
      "Average validation loss: 0.007446860894560814\n",
      "4/4 [==============================] - 29s 812ms/step - loss: 6.5115e-04 - val_loss: 0.0351\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 32s 788ms/step - loss: 5.8989e-04 - val_loss: 0.0351\n",
      "Average validation loss: 0.011534943245351315\n",
      "4/4 [==============================] - 32s 808ms/step - loss: 5.8989e-04 - val_loss: 0.0328\n",
      "Train loss: 0.0005898946335719301, Validation loss: 0.03278526933863759\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 2.6567e-04\n",
      "Average validation loss: 0.00013325002510100603\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 2.6567e-04 - val_loss: 1.3325e-04\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 679ms/step - loss: 1.7596e-04 - val_loss: 1.3325e-04\n",
      "Average validation loss: 0.0\n",
      "4/4 [==============================] - 6s 689ms/step - loss: 1.7596e-04 - val_loss: 6.6625e-05\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 9s 683ms/step - loss: 1.3106e-04 - val_loss: 6.6625e-05\n",
      "Average validation loss: 0.0\n",
      "4/4 [==============================] - 9s 695ms/step - loss: 1.3106e-04 - val_loss: 4.4417e-05\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 11s 701ms/step - loss: 1.0620e-04 - val_loss: 4.4417e-05\n",
      "Average validation loss: 0.0\n",
      "4/4 [==============================] - 11s 712ms/step - loss: 1.0620e-04 - val_loss: 3.3313e-05\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 14s 701ms/step - loss: 9.0427e-05 - val_loss: 3.3313e-05\n",
      "Average validation loss: 6.208665137563685e-09\n",
      "4/4 [==============================] - 14s 711ms/step - loss: 9.0427e-05 - val_loss: 2.6651e-05\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 17s 694ms/step - loss: 7.8996e-05 - val_loss: 2.6651e-05\n",
      "Average validation loss: 7.535446457040962e-06\n",
      "4/4 [==============================] - 17s 706ms/step - loss: 7.8996e-05 - val_loss: 2.3465e-05\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 20s 683ms/step - loss: 7.0424e-05 - val_loss: 2.3465e-05\n",
      "Average validation loss: 0.0007795484270900488\n",
      "4/4 [==============================] - 20s 695ms/step - loss: 7.0424e-05 - val_loss: 1.3148e-04\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 23s 735ms/step - loss: 6.3799e-05 - val_loss: 1.3148e-04\n",
      "Average validation loss: 0.0006880337023176253\n",
      "4/4 [==============================] - 23s 747ms/step - loss: 6.3799e-05 - val_loss: 2.0105e-04\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 26s 699ms/step - loss: 5.8629e-05 - val_loss: 2.0105e-04\n",
      "Average validation loss: 0.07341434061527252\n",
      "4/4 [==============================] - 26s 711ms/step - loss: 5.8629e-05 - val_loss: 0.0083    \n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 29s 683ms/step - loss: 5.4309e-05 - val_loss: 0.0083\n",
      "Average validation loss: 0.16334253549575806\n",
      "4/4 [==============================] - 29s 695ms/step - loss: 5.4309e-05 - val_loss: 0.0238\n",
      "Train loss: 5.430942067903288e-05, Validation loss: 0.023836524992066142\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 4.7227e-07\n",
      "Average validation loss: 0.044366251677274704\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 4.7227e-07 - val_loss: 0.0444\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 688ms/step - loss: 3.0504e-07 - val_loss: 0.0444\n",
      "Average validation loss: 0.036835283041000366\n",
      "4/4 [==============================] - 6s 700ms/step - loss: 3.0504e-07 - val_loss: 0.0406\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 8s 706ms/step - loss: 2.9951e-07 - val_loss: 0.0406\n",
      "Average validation loss: 0.03840428590774536\n",
      "4/4 [==============================] - 8s 718ms/step - loss: 2.9951e-07 - val_loss: 0.0399\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 11s 699ms/step - loss: 2.3387e-07 - val_loss: 0.0399\n",
      "Average validation loss: 0.07106009125709534\n",
      "4/4 [==============================] - 11s 711ms/step - loss: 2.3387e-07 - val_loss: 0.0477\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 14s 749ms/step - loss: 1.9410e-07 - val_loss: 0.0477\n",
      "Average validation loss: 0.08612385392189026\n",
      "4/4 [==============================] - 14s 766ms/step - loss: 1.9410e-07 - val_loss: 0.0554\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 17s 684ms/step - loss: 1.6983e-07 - val_loss: 0.0554\n",
      "Average validation loss: 0.1134151816368103\n",
      "4/4 [==============================] - 17s 701ms/step - loss: 1.6983e-07 - val_loss: 0.0650\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 20s 656ms/step - loss: 1.4876e-07 - val_loss: 0.0650\n",
      "Average validation loss: 0.1086835116147995\n",
      "4/4 [==============================] - 20s 673ms/step - loss: 1.4876e-07 - val_loss: 0.0713\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 23s 695ms/step - loss: 2.9600e-07 - val_loss: 0.0713\n",
      "Average validation loss: 0.088285431265831\n",
      "4/4 [==============================] - 23s 707ms/step - loss: 2.9600e-07 - val_loss: 0.0734\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 25s 682ms/step - loss: 2.6945e-07 - val_loss: 0.0734\n",
      "Average validation loss: 0.10815358906984329\n",
      "4/4 [==============================] - 25s 695ms/step - loss: 2.6945e-07 - val_loss: 0.0773\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 28s 700ms/step - loss: 2.4300e-07 - val_loss: 0.0773\n",
      "Average validation loss: 0.09213808178901672\n",
      "4/4 [==============================] - 28s 711ms/step - loss: 2.4300e-07 - val_loss: 0.0787\n",
      "Train loss: 2.4300285281775304e-07, Validation loss: 0.07874655611813068\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 1.0886e-05\n",
      "Average validation loss: 0.0\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 1.0886e-05 - val_loss: 0.0000e+00\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_5.pth'.\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 675ms/step - loss: 1.1139e-05 - val_loss: 0.0000e+00\n",
      "Average validation loss: 6.823483555962184e-09\n",
      "4/4 [==============================] - 6s 688ms/step - loss: 1.1139e-05 - val_loss: 3.4117e-09\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 8s 695ms/step - loss: 1.1115e-05 - val_loss: 3.4117e-09\n",
      "Average validation loss: 2.1029291019658558e-07\n",
      "4/4 [==============================] - 8s 710ms/step - loss: 1.1115e-05 - val_loss: 7.2372e-08\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 11s 685ms/step - loss: 1.0986e-05 - val_loss: 7.2372e-08\n",
      "Average validation loss: 1.142382970442668e-07\n",
      "4/4 [==============================] - 11s 702ms/step - loss: 1.0986e-05 - val_loss: 8.2839e-08\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 14s 704ms/step - loss: 1.0807e-05 - val_loss: 8.2839e-08\n",
      "Average validation loss: 5.2957499718786494e-08\n",
      "4/4 [==============================] - 14s 713ms/step - loss: 1.0807e-05 - val_loss: 7.6862e-08\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 17s 679ms/step - loss: 1.0653e-05 - val_loss: 7.6862e-08\n",
      "Average validation loss: 6.564464456459973e-07\n",
      "4/4 [==============================] - 17s 692ms/step - loss: 1.0653e-05 - val_loss: 1.7346e-07\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 20s 699ms/step - loss: 1.0576e-05 - val_loss: 1.7346e-07\n",
      "Average validation loss: 4.758637714985525e-07\n",
      "4/4 [==============================] - 20s 712ms/step - loss: 1.0576e-05 - val_loss: 2.1666e-07\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 23s 699ms/step - loss: 1.0450e-05 - val_loss: 2.1666e-07\n",
      "Average validation loss: 2.8378030592079995e-08\n",
      "4/4 [==============================] - 23s 711ms/step - loss: 1.0450e-05 - val_loss: 1.9313e-07\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 25s 696ms/step - loss: 1.0351e-05 - val_loss: 1.9313e-07\n",
      "Average validation loss: 6.612774683389944e-08\n",
      "4/4 [==============================] - 25s 703ms/step - loss: 1.0351e-05 - val_loss: 1.7901e-07\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 28s 700ms/step - loss: 1.0265e-05 - val_loss: 1.7901e-07\n",
      "Average validation loss: 4.369859141206689e-07\n",
      "4/4 [==============================] - 28s 713ms/step - loss: 1.0265e-05 - val_loss: 2.0481e-07\n",
      "Train loss: 1.0264856934733002e-05, Validation loss: 2.0481140992067992e-07\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "1/8 [==>...........................] - ETA: 5s - loss: 3.9435e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 712ms/step - loss: 4.7869e-05\n",
      "Average validation loss: 0.0\n",
      "8/8 [==============================] - 6s 723ms/step - loss: 4.7869e-05 - val_loss: 0.0000e+00\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 12s 724ms/step - loss: 4.7624e-05 - val_loss: 0.0000e+00\n",
      "Average validation loss: 0.0\n",
      "8/8 [==============================] - 12s 736ms/step - loss: 4.7624e-05 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 707ms/step - loss: 4.6911e-05 - val_loss: 0.0000e+00\n",
      "Average validation loss: 0.0\n",
      "8/8 [==============================] - 17s 717ms/step - loss: 4.6911e-05 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 707ms/step - loss: 4.6259e-05 - val_loss: 0.0000e+00\n",
      "Average validation loss: 0.00024319659860339016\n",
      "8/8 [==============================] - 23s 716ms/step - loss: 4.6259e-05 - val_loss: 6.0799e-05\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 29s 702ms/step - loss: 4.5907e-05 - val_loss: 6.0799e-05\n",
      "Average validation loss: 1.2920935660076793e-05\n",
      "8/8 [==============================] - 29s 716ms/step - loss: 4.5907e-05 - val_loss: 5.1224e-05\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 35s 708ms/step - loss: 4.5647e-05 - val_loss: 5.1224e-05\n",
      "Average validation loss: 2.1950978407403454e-05\n",
      "8/8 [==============================] - 35s 720ms/step - loss: 4.5647e-05 - val_loss: 4.6345e-05\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 716ms/step - loss: 4.5423e-05 - val_loss: 4.6345e-05\n",
      "Average validation loss: 0.000542617795872502\n",
      "8/8 [==============================] - 40s 726ms/step - loss: 4.5423e-05 - val_loss: 1.1724e-04\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 46s 738ms/step - loss: 4.5236e-05 - val_loss: 1.1724e-04\n",
      "Average validation loss: 5.246672117209528e-06\n",
      "8/8 [==============================] - 46s 750ms/step - loss: 4.5236e-05 - val_loss: 1.0324e-04\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 52s 711ms/step - loss: 4.5043e-05 - val_loss: 1.0324e-04\n",
      "Average validation loss: 3.6803217881242745e-05\n",
      "8/8 [==============================] - 52s 723ms/step - loss: 4.5043e-05 - val_loss: 9.5860e-05\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 58s 700ms/step - loss: 4.4786e-05 - val_loss: 9.5860e-05\n",
      "Average validation loss: 5.769181825598935e-06\n",
      "8/8 [==============================] - 58s 712ms/step - loss: 4.4786e-05 - val_loss: 8.6851e-05\n",
      "Train loss: 4.478594304109518e-05, Validation loss: 8.685053803674237e-05\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 3.5201e-05\n",
      "Average validation loss: 0.14050645381212234\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 3.5201e-05 - val_loss: 0.1405\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 698ms/step - loss: 3.5935e-05 - val_loss: 0.1405\n",
      "Average validation loss: 0.16028554737567902\n",
      "8/8 [==============================] - 11s 714ms/step - loss: 3.5935e-05 - val_loss: 0.1504\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 678ms/step - loss: 3.4876e-05 - val_loss: 0.1504\n",
      "Average validation loss: 0.0667178425937891\n",
      "8/8 [==============================] - 17s 690ms/step - loss: 3.4876e-05 - val_loss: 0.1225\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 22s 693ms/step - loss: 3.4331e-05 - val_loss: 0.1225\n",
      "Average validation loss: 0.10261323302984238\n",
      "8/8 [==============================] - 23s 708ms/step - loss: 3.4331e-05 - val_loss: 0.1175\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 28s 691ms/step - loss: 3.4027e-05 - val_loss: 0.1175\n",
      "Average validation loss: 0.07716375216841698\n",
      "8/8 [==============================] - 28s 703ms/step - loss: 3.4027e-05 - val_loss: 0.1095\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 34s 704ms/step - loss: 3.3648e-05 - val_loss: 0.1095\n",
      "Average validation loss: 0.11300953105092049\n",
      "8/8 [==============================] - 34s 719ms/step - loss: 3.3648e-05 - val_loss: 0.1100\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 39s 706ms/step - loss: 3.3775e-05 - val_loss: 0.1100\n",
      "Average validation loss: 0.15317361801862717\n",
      "8/8 [==============================] - 40s 718ms/step - loss: 3.3775e-05 - val_loss: 0.1162\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 45s 702ms/step - loss: 3.3523e-05 - val_loss: 0.1162\n",
      "Average validation loss: 0.5912502706050873\n",
      "8/8 [==============================] - 45s 711ms/step - loss: 3.3523e-05 - val_loss: 0.1756\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 51s 701ms/step - loss: 3.3150e-05 - val_loss: 0.1756\n",
      "Average validation loss: 0.4146476984024048\n",
      "8/8 [==============================] - 51s 710ms/step - loss: 3.3150e-05 - val_loss: 0.2022\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 56s 691ms/step - loss: 3.3019e-05 - val_loss: 0.2022\n",
      "Average validation loss: 0.2840169221162796\n",
      "8/8 [==============================] - 57s 702ms/step - loss: 3.3019e-05 - val_loss: 0.2103\n",
      "Train loss: 3.3019139781608614e-05, Validation loss: 0.2103384869173169\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 3.9256e-05\n",
      "Average validation loss: 0.07079076399397621\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 3.9256e-05 - val_loss: 0.0708\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 707ms/step - loss: 3.8601e-05 - val_loss: 0.0708\n",
      "Average validation loss: 0.019948240602388978\n",
      "8/8 [==============================] - 12s 716ms/step - loss: 3.8601e-05 - val_loss: 0.0454\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 728ms/step - loss: 3.7689e-05 - val_loss: 0.0454\n",
      "Average validation loss: 0.04737827714779996\n",
      "8/8 [==============================] - 18s 740ms/step - loss: 3.7689e-05 - val_loss: 0.0460\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 695ms/step - loss: 3.7097e-05 - val_loss: 0.0460\n",
      "Average validation loss: 0.038240626265178435\n",
      "8/8 [==============================] - 23s 707ms/step - loss: 3.7097e-05 - val_loss: 0.0441\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 29s 713ms/step - loss: 3.6978e-05 - val_loss: 0.0441\n",
      "Average validation loss: 0.077870602340681\n",
      "8/8 [==============================] - 29s 722ms/step - loss: 3.6978e-05 - val_loss: 0.0508\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 35s 700ms/step - loss: 3.7070e-05 - val_loss: 0.0508\n",
      "Average validation loss: 0.1421247273683548\n",
      "8/8 [==============================] - 35s 709ms/step - loss: 3.7070e-05 - val_loss: 0.0661\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 693ms/step - loss: 3.7603e-05 - val_loss: 0.0661\n",
      "Average validation loss: 0.1267811388570408\n",
      "8/8 [==============================] - 40s 705ms/step - loss: 3.7603e-05 - val_loss: 0.0747\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 46s 703ms/step - loss: 3.7458e-05 - val_loss: 0.0747\n",
      "Average validation loss: 0.08872525591868907\n",
      "8/8 [==============================] - 46s 715ms/step - loss: 3.7458e-05 - val_loss: 0.0765\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 52s 711ms/step - loss: 3.7159e-05 - val_loss: 0.0765\n",
      "Average validation loss: 0.10710568163312928\n",
      "8/8 [==============================] - 52s 721ms/step - loss: 3.7159e-05 - val_loss: 0.0799\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 58s 722ms/step - loss: 3.6838e-05 - val_loss: 0.0799\n",
      "Average validation loss: 0.04511662544416595\n",
      "8/8 [==============================] - 58s 732ms/step - loss: 3.6838e-05 - val_loss: 0.0764\n",
      "Train loss: 3.683846795076336e-05, Validation loss: 0.07640819395714045\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 2.4050e-05\n",
      "Average validation loss: 0.07082640007138252\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 2.4050e-05 - val_loss: 0.0708\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 697ms/step - loss: 2.3101e-05 - val_loss: 0.0708\n",
      "Average validation loss: 0.12986267358064651\n",
      "8/8 [==============================] - 11s 707ms/step - loss: 2.3101e-05 - val_loss: 0.1003\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 695ms/step - loss: 2.2539e-05 - val_loss: 0.1003\n",
      "Average validation loss: 0.2391810268163681\n",
      "8/8 [==============================] - 17s 705ms/step - loss: 2.2539e-05 - val_loss: 0.1466\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 693ms/step - loss: 2.2345e-05 - val_loss: 0.1466\n",
      "Average validation loss: 0.2502262443304062\n",
      "8/8 [==============================] - 23s 708ms/step - loss: 2.2345e-05 - val_loss: 0.1725\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 28s 695ms/step - loss: 2.2232e-05 - val_loss: 0.1725\n",
      "Average validation loss: 0.24610436707735062\n",
      "8/8 [==============================] - 28s 705ms/step - loss: 2.2232e-05 - val_loss: 0.1872\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 34s 705ms/step - loss: 2.2129e-05 - val_loss: 0.1872\n",
      "Average validation loss: 0.26801253855228424\n",
      "8/8 [==============================] - 34s 715ms/step - loss: 2.2129e-05 - val_loss: 0.2007\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 698ms/step - loss: 2.2247e-05 - val_loss: 0.2007\n",
      "Average validation loss: 0.16334688663482666\n",
      "8/8 [==============================] - 40s 708ms/step - loss: 2.2247e-05 - val_loss: 0.1954\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 45s 701ms/step - loss: 2.2238e-05 - val_loss: 0.1954\n",
      "Average validation loss: 0.09313652291893959\n",
      "8/8 [==============================] - 45s 712ms/step - loss: 2.2238e-05 - val_loss: 0.1826\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 51s 723ms/step - loss: 2.2267e-05 - val_loss: 0.1826\n",
      "Average validation loss: 0.06118783913552761\n",
      "8/8 [==============================] - 51s 735ms/step - loss: 2.2267e-05 - val_loss: 0.1691\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 57s 705ms/step - loss: 2.2285e-05 - val_loss: 0.1691\n",
      "Average validation loss: 0.13958997279405594\n",
      "8/8 [==============================] - 57s 714ms/step - loss: 2.2285e-05 - val_loss: 0.1661\n",
      "Train loss: 2.2284812640860483e-05, Validation loss: 0.1661474471911788\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 6s 700ms/step - loss: 3.3265e-05\n",
      "Average validation loss: 0.1254640519618988\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 3.3265e-05 - val_loss: 0.1255\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 696ms/step - loss: 3.2491e-05 - val_loss: 0.1255\n",
      "Average validation loss: 0.09499114762184034\n",
      "8/8 [==============================] - 11s 707ms/step - loss: 3.2491e-05 - val_loss: 0.1102\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 700ms/step - loss: 3.3287e-05 - val_loss: 0.1102\n",
      "Average validation loss: 0.07027717032624992\n",
      "8/8 [==============================] - 17s 709ms/step - loss: 3.3287e-05 - val_loss: 0.0969\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 23s 702ms/step - loss: 3.2906e-05 - val_loss: 0.0969\n",
      "Average validation loss: 0.04540382097366091\n",
      "8/8 [==============================] - 23s 714ms/step - loss: 3.2906e-05 - val_loss: 0.0840\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 28s 690ms/step - loss: 3.1973e-05 - val_loss: 0.0840\n",
      "Average validation loss: 0.11155307238764767\n",
      "8/8 [==============================] - 28s 703ms/step - loss: 3.1973e-05 - val_loss: 0.0895\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 34s 707ms/step - loss: 3.1148e-05 - val_loss: 0.0895\n",
      "Average validation loss: 0.31712713837623596\n",
      "8/8 [==============================] - 34s 719ms/step - loss: 3.1148e-05 - val_loss: 0.1275\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 40s 689ms/step - loss: 3.1130e-05 - val_loss: 0.1275\n",
      "Average validation loss: 0.23915022611987524\n",
      "8/8 [==============================] - 40s 703ms/step - loss: 3.1130e-05 - val_loss: 0.1434\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 45s 702ms/step - loss: 3.0857e-05 - val_loss: 0.1434\n",
      "Average validation loss: 0.12719227470919137\n",
      "8/8 [==============================] - 46s 712ms/step - loss: 3.0857e-05 - val_loss: 0.1414\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 51s 695ms/step - loss: 3.0394e-05 - val_loss: 0.1414\n",
      "Average validation loss: 0.025615845073843957\n",
      "8/8 [==============================] - 51s 710ms/step - loss: 3.0394e-05 - val_loss: 0.1285\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_10.pth'.\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 57s 696ms/step - loss: 2.9974e-05 - val_loss: 0.1285\n",
      "Average validation loss: 0.06532149456899816\n",
      "8/8 [==============================] - 57s 705ms/step - loss: 2.9974e-05 - val_loss: 0.1222\n",
      "Train loss: 2.997379012153996e-05, Validation loss: 0.12220962421194423\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      " 1/80 [..............................] - ETA: 55s - loss: 2.1870e-07"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 57s 707ms/step - loss: 3.1786e-04\n",
      "Average validation loss: 0.29797053039073945\n",
      "80/80 [==============================] - 57s 717ms/step - loss: 3.1786e-04 - val_loss: 0.2980\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 114s 704ms/step - loss: 2.9447e-04 - val_loss: 0.2980\n",
      "Average validation loss: 0.16759274173527955\n",
      "80/80 [==============================] - 115s 714ms/step - loss: 2.9447e-04 - val_loss: 0.2328\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 171s 708ms/step - loss: 2.6067e-04 - val_loss: 0.2328\n",
      "Average validation loss: 0.21675692312419415\n",
      "80/80 [==============================] - 172s 718ms/step - loss: 2.6067e-04 - val_loss: 0.2274\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 228s 704ms/step - loss: 2.4743e-04 - val_loss: 0.2274\n",
      "Average validation loss: 0.11312161795794964\n",
      "80/80 [==============================] - 229s 714ms/step - loss: 2.4743e-04 - val_loss: 0.1989\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 286s 712ms/step - loss: 2.3455e-04 - val_loss: 0.1989\n",
      "Average validation loss: 0.08542686998844147\n",
      "80/80 [==============================] - 287s 722ms/step - loss: 2.3455e-04 - val_loss: 0.1762\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 343s 701ms/step - loss: 2.2144e-04 - val_loss: 0.1762\n",
      "Average validation loss: 0.03999581625685096\n",
      "80/80 [==============================] - 344s 710ms/step - loss: 2.2144e-04 - val_loss: 0.1535\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 400s 703ms/step - loss: 2.1332e-04 - val_loss: 0.1535\n",
      "Average validation loss: 0.058953572250902656\n",
      "80/80 [==============================] - 401s 713ms/step - loss: 2.1332e-04 - val_loss: 0.1400\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 457s 703ms/step - loss: 2.0658e-04 - val_loss: 0.1400\n",
      "Average validation loss: 0.06996608786284923\n",
      "80/80 [==============================] - 458s 713ms/step - loss: 2.0658e-04 - val_loss: 0.1312\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 514s 701ms/step - loss: 2.0047e-04 - val_loss: 0.1312\n",
      "Average validation loss: 0.07161969067528844\n",
      "80/80 [==============================] - 515s 711ms/step - loss: 2.0047e-04 - val_loss: 0.1246\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 571s 702ms/step - loss: 1.9532e-04 - val_loss: 0.1246\n",
      "Average validation loss: 0.08551814705133438\n",
      "80/80 [==============================] - 572s 712ms/step - loss: 1.9532e-04 - val_loss: 0.1207\n",
      "Train loss: 0.00019531587269658868, Validation loss: 0.12069219972938298\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 56s 705ms/step - loss: 1.6006e-04\n",
      "Average validation loss: 0.07130404748022556\n",
      "80/80 [==============================] - 57s 715ms/step - loss: 1.6006e-04 - val_loss: 0.0713\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 113s 699ms/step - loss: 1.5080e-04 - val_loss: 0.0713\n",
      "Average validation loss: 0.03523734319023788\n",
      "80/80 [==============================] - 114s 709ms/step - loss: 1.5080e-04 - val_loss: 0.0533\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 171s 708ms/step - loss: 1.4731e-04 - val_loss: 0.0533\n",
      "Average validation loss: 0.03591410727240145\n",
      "80/80 [==============================] - 172s 718ms/step - loss: 1.4731e-04 - val_loss: 0.0475\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 228s 708ms/step - loss: 1.4374e-04 - val_loss: 0.0475\n",
      "Average validation loss: 0.03886919361539185\n",
      "80/80 [==============================] - 229s 718ms/step - loss: 1.4374e-04 - val_loss: 0.0453\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 285s 705ms/step - loss: 1.4831e-04 - val_loss: 0.0453\n",
      "Average validation loss: 0.2882303226739168\n",
      "80/80 [==============================] - 286s 715ms/step - loss: 1.4831e-04 - val_loss: 0.0939\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 343s 703ms/step - loss: 1.4956e-04 - val_loss: 0.0939\n",
      "Average validation loss: 0.4203178584575653\n",
      "80/80 [==============================] - 343s 713ms/step - loss: 1.4956e-04 - val_loss: 0.1483\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 400s 704ms/step - loss: 1.4912e-04 - val_loss: 0.1483\n",
      "Average validation loss: 0.37869930975139143\n",
      "80/80 [==============================] - 400s 714ms/step - loss: 1.4912e-04 - val_loss: 0.1812\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 457s 702ms/step - loss: 1.4741e-04 - val_loss: 0.1812\n",
      "Average validation loss: 0.21742273159325123\n",
      "80/80 [==============================] - 457s 712ms/step - loss: 1.4741e-04 - val_loss: 0.1857\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 514s 703ms/step - loss: 1.4563e-04 - val_loss: 0.1857\n",
      "Average validation loss: 0.18165269549936056\n",
      "80/80 [==============================] - 515s 713ms/step - loss: 1.4563e-04 - val_loss: 0.1853\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 571s 709ms/step - loss: 1.4343e-04 - val_loss: 0.1853\n",
      "Average validation loss: 0.2208397515118122\n",
      "80/80 [==============================] - 572s 720ms/step - loss: 1.4343e-04 - val_loss: 0.1888\n",
      "Train loss: 0.00014343098145735256, Validation loss: 0.1888487361045554\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 63s 789ms/step - loss: 1.2946e-04\n",
      "Average validation loss: 0.05376710930431727\n",
      "80/80 [==============================] - 64s 800ms/step - loss: 1.2946e-04 - val_loss: 0.0538\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 127s 791ms/step - loss: 1.2764e-04 - val_loss: 0.0538\n",
      "Average validation loss: 0.2755073984446596\n",
      "80/80 [==============================] - 128s 802ms/step - loss: 1.2764e-04 - val_loss: 0.1646\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 185s 713ms/step - loss: 1.2673e-04 - val_loss: 0.1646\n",
      "Average validation loss: 0.318597599321787\n",
      "80/80 [==============================] - 186s 723ms/step - loss: 1.2673e-04 - val_loss: 0.2160\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 243s 706ms/step - loss: 1.2649e-04 - val_loss: 0.2160\n",
      "Average validation loss: 0.1768673075134018\n",
      "80/80 [==============================] - 244s 716ms/step - loss: 1.2649e-04 - val_loss: 0.2062\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 300s 705ms/step - loss: 1.2367e-04 - val_loss: 0.2062\n",
      "Average validation loss: 0.3103855181518497\n",
      "80/80 [==============================] - 301s 716ms/step - loss: 1.2367e-04 - val_loss: 0.2270\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 358s 707ms/step - loss: 1.2212e-04 - val_loss: 0.2270\n",
      "Average validation loss: 0.06715409754833672\n",
      "80/80 [==============================] - 358s 717ms/step - loss: 1.2212e-04 - val_loss: 0.2004\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 415s 704ms/step - loss: 1.2088e-04 - val_loss: 0.2004\n",
      "Average validation loss: 0.04261162527836859\n",
      "80/80 [==============================] - 416s 715ms/step - loss: 1.2088e-04 - val_loss: 0.1778\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 473s 716ms/step - loss: 1.2192e-04 - val_loss: 0.1778\n",
      "Average validation loss: 0.060351401148363945\n",
      "80/80 [==============================] - 474s 726ms/step - loss: 1.2192e-04 - val_loss: 0.1632\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 531s 712ms/step - loss: 1.2166e-04 - val_loss: 0.1632\n",
      "Average validation loss: 0.03218678245320916\n",
      "80/80 [==============================] - 532s 723ms/step - loss: 1.2166e-04 - val_loss: 0.1486\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 588s 703ms/step - loss: 1.2034e-04 - val_loss: 0.1486\n",
      "Average validation loss: 0.17797147184610368\n",
      "80/80 [==============================] - 589s 713ms/step - loss: 1.2034e-04 - val_loss: 0.1515\n",
      "Train loss: 0.0001203426048835299, Validation loss: 0.15154003110103975\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 57s 706ms/step - loss: 1.0366e-04\n",
      "Average validation loss: 0.08851016662083566\n",
      "80/80 [==============================] - 57s 716ms/step - loss: 1.0366e-04 - val_loss: 0.0885\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 114s 708ms/step - loss: 1.0500e-04 - val_loss: 0.0885\n",
      "Average validation loss: 0.07569606997421943\n",
      "80/80 [==============================] - 115s 719ms/step - loss: 1.0500e-04 - val_loss: 0.0821\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 171s 702ms/step - loss: 1.0211e-04 - val_loss: 0.0821\n",
      "Average validation loss: 0.09419332625693641\n",
      "80/80 [==============================] - 172s 712ms/step - loss: 1.0211e-04 - val_loss: 0.0861\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 228s 708ms/step - loss: 1.0023e-04 - val_loss: 0.0861\n",
      "Average validation loss: 0.04123752485029399\n",
      "80/80 [==============================] - 229s 718ms/step - loss: 1.0023e-04 - val_loss: 0.0749\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 286s 703ms/step - loss: 9.8606e-05 - val_loss: 0.0749\n",
      "Average validation loss: 0.06984993561636657\n",
      "80/80 [==============================] - 286s 713ms/step - loss: 9.8606e-05 - val_loss: 0.0739\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 343s 703ms/step - loss: 9.7991e-05 - val_loss: 0.0739\n",
      "Average validation loss: 0.09929091701997095\n",
      "80/80 [==============================] - 343s 713ms/step - loss: 9.7991e-05 - val_loss: 0.0781\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 400s 709ms/step - loss: 9.6535e-05 - val_loss: 0.0781\n",
      "Average validation loss: 0.033293383778072894\n",
      "80/80 [==============================] - 401s 720ms/step - loss: 9.6535e-05 - val_loss: 0.0717\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 457s 703ms/step - loss: 9.6176e-05 - val_loss: 0.0717\n",
      "Average validation loss: 0.09407808349933475\n",
      "80/80 [==============================] - 458s 714ms/step - loss: 9.6176e-05 - val_loss: 0.0745\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 514s 704ms/step - loss: 9.7260e-05 - val_loss: 0.0745\n",
      "Average validation loss: 0.0451503723859787\n",
      "80/80 [==============================] - 515s 714ms/step - loss: 9.7260e-05 - val_loss: 0.0713\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 571s 701ms/step - loss: 9.8234e-05 - val_loss: 0.0713\n",
      "Average validation loss: 0.04065218152245507\n",
      "80/80 [==============================] - 572s 711ms/step - loss: 9.8234e-05 - val_loss: 0.0682\n",
      "Train loss: 9.823382244163959e-05, Validation loss: 0.06819519615244644\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 57s 713ms/step - loss: 1.0160e-04\n",
      "Average validation loss: 0.10950463673798368\n",
      "80/80 [==============================] - 58s 723ms/step - loss: 1.0160e-04 - val_loss: 0.1095\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 114s 703ms/step - loss: 9.9857e-05 - val_loss: 0.1095\n",
      "Average validation loss: 0.11942598068562801\n",
      "80/80 [==============================] - 115s 713ms/step - loss: 9.9857e-05 - val_loss: 0.1145\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 172s 715ms/step - loss: 9.9550e-05 - val_loss: 0.1145\n",
      "Average validation loss: 0.08285736162215471\n",
      "80/80 [==============================] - 173s 725ms/step - loss: 9.9550e-05 - val_loss: 0.1039\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 230s 715ms/step - loss: 9.6109e-05 - val_loss: 0.1039\n",
      "Average validation loss: 0.036023578885942695\n",
      "80/80 [==============================] - 231s 724ms/step - loss: 9.6109e-05 - val_loss: 0.0870\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_100.pth'.\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 286s 694ms/step - loss: 9.5366e-05 - val_loss: 0.0870\n",
      "Average validation loss: 0.4166645879148746\n",
      "80/80 [==============================] - 287s 704ms/step - loss: 9.5366e-05 - val_loss: 0.1529\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 343s 703ms/step - loss: 9.5264e-05 - val_loss: 0.1529\n",
      "Average validation loss: 0.3586034081876278\n",
      "80/80 [==============================] - 344s 713ms/step - loss: 9.5264e-05 - val_loss: 0.1872\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 401s 705ms/step - loss: 9.5477e-05 - val_loss: 0.1872\n",
      "Average validation loss: 0.12625960569712333\n",
      "80/80 [==============================] - 401s 715ms/step - loss: 9.5477e-05 - val_loss: 0.1785\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 458s 711ms/step - loss: 1.1841e-04 - val_loss: 0.1785\n",
      "Average validation loss: 0.614084069430828\n",
      "80/80 [==============================] - 459s 722ms/step - loss: 1.1841e-04 - val_loss: 0.2329\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 516s 706ms/step - loss: 1.4160e-04 - val_loss: 0.2329\n",
      "Average validation loss: 0.25464612277908716\n",
      "80/80 [==============================] - 516s 717ms/step - loss: 1.4160e-04 - val_loss: 0.2353\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 572s 701ms/step - loss: 1.5628e-04 - val_loss: 0.2353\n",
      "Average validation loss: 0.12314963943790644\n",
      "80/80 [==============================] - 573s 711ms/step - loss: 1.5628e-04 - val_loss: 0.2241\n",
      "Train loss: 0.00015628492544275785, Validation loss: 0.22412189913791564\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "  1/160 [..............................] - ETA: 1:50 - loss: 2.5448e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 112s 701ms/step - loss: 1.7088e-04\n",
      "Average validation loss: 0.051809812989085914\n",
      "160/160 [==============================] - 114s 712ms/step - loss: 1.7088e-04 - val_loss: 0.0518\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 226s 700ms/step - loss: 1.4646e-04 - val_loss: 0.0518\n",
      "Average validation loss: 0.04839502845425159\n",
      "160/160 [==============================] - 227s 710ms/step - loss: 1.4646e-04 - val_loss: 0.0501\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 340s 705ms/step - loss: 1.3407e-04 - val_loss: 0.0501\n",
      "Average validation loss: 0.09549857043311931\n",
      "160/160 [==============================] - 342s 714ms/step - loss: 1.3407e-04 - val_loss: 0.0652\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 456s 715ms/step - loss: 1.2883e-04 - val_loss: 0.0652\n",
      "Average validation loss: 0.048998799873515964\n",
      "160/160 [==============================] - 458s 725ms/step - loss: 1.2883e-04 - val_loss: 0.0612\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 570s 701ms/step - loss: 1.2356e-04 - val_loss: 0.0612\n",
      "Average validation loss: 0.04404038629727438\n",
      "160/160 [==============================] - 572s 711ms/step - loss: 1.2356e-04 - val_loss: 0.0577\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 684s 702ms/step - loss: 1.1930e-04 - val_loss: 0.0577\n",
      "Average validation loss: 0.03295329482061789\n",
      "160/160 [==============================] - 686s 712ms/step - loss: 1.1930e-04 - val_loss: 0.0536\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 799s 709ms/step - loss: 1.1543e-04 - val_loss: 0.0536\n",
      "Average validation loss: 0.09251409487333148\n",
      "160/160 [==============================] - 801s 719ms/step - loss: 1.1543e-04 - val_loss: 0.0592\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 914s 708ms/step - loss: 1.1278e-04 - val_loss: 0.0592\n",
      "Average validation loss: 0.040821695770137015\n",
      "160/160 [==============================] - 915s 717ms/step - loss: 1.1278e-04 - val_loss: 0.0569\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1029s 711ms/step - loss: 1.1050e-04 - val_loss: 0.0569\n",
      "Average validation loss: 0.12898940220475197\n",
      "160/160 [==============================] - 1031s 721ms/step - loss: 1.1050e-04 - val_loss: 0.0649\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1157s 787ms/step - loss: 1.0844e-04 - val_loss: 0.0649\n",
      "Average validation loss: 0.03293364781420678\n",
      "160/160 [==============================] - 1158s 798ms/step - loss: 1.0844e-04 - val_loss: 0.0617\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Train loss: 0.00010843909664990602, Validation loss: 0.06169547335302923\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 126s 786ms/step - loss: 9.8626e-05\n",
      "Average validation loss: 0.06555457971990108\n",
      "160/160 [==============================] - 128s 797ms/step - loss: 9.8626e-05 - val_loss: 0.0656\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 255s 794ms/step - loss: 9.6854e-05 - val_loss: 0.0656\n",
      "Average validation loss: 0.04713878503534943\n",
      "160/160 [==============================] - 256s 805ms/step - loss: 9.6854e-05 - val_loss: 0.0563\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 383s 792ms/step - loss: 9.8384e-05 - val_loss: 0.0563\n",
      "Average validation loss: 0.04896205435506999\n",
      "160/160 [==============================] - 385s 803ms/step - loss: 9.8384e-05 - val_loss: 0.0539\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 511s 788ms/step - loss: 9.6419e-05 - val_loss: 0.0539\n",
      "Average validation loss: 0.08686156757175922\n",
      "160/160 [==============================] - 513s 799ms/step - loss: 9.6419e-05 - val_loss: 0.0621\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 638s 785ms/step - loss: 9.5544e-05 - val_loss: 0.0621\n",
      "Average validation loss: 0.045569236809387806\n",
      "160/160 [==============================] - 640s 796ms/step - loss: 9.5544e-05 - val_loss: 0.0588\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 766s 785ms/step - loss: 9.4711e-05 - val_loss: 0.0588\n",
      "Average validation loss: 0.07732555880211293\n",
      "160/160 [==============================] - 768s 796ms/step - loss: 9.4711e-05 - val_loss: 0.0619\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 894s 788ms/step - loss: 9.4753e-05 - val_loss: 0.0619\n",
      "Average validation loss: 0.13011844852007926\n",
      "160/160 [==============================] - 895s 799ms/step - loss: 9.4753e-05 - val_loss: 0.0716\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1022s 789ms/step - loss: 9.5241e-05 - val_loss: 0.0716\n",
      "Average validation loss: 0.03172073275782168\n",
      "160/160 [==============================] - 1023s 799ms/step - loss: 9.5241e-05 - val_loss: 0.0667\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1149s 788ms/step - loss: 9.4530e-05 - val_loss: 0.0667\n",
      "Average validation loss: 0.028617563913576304\n",
      "160/160 [==============================] - 1151s 799ms/step - loss: 9.4530e-05 - val_loss: 0.0624\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1277s 787ms/step - loss: 9.3678e-05 - val_loss: 0.0624\n",
      "Average validation loss: 0.045885649090632794\n",
      "160/160 [==============================] - 1279s 798ms/step - loss: 9.3678e-05 - val_loss: 0.0608\n",
      "Train loss: 9.367832829640126e-05, Validation loss: 0.06077541765756904\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 126s 787ms/step - loss: 9.3203e-05\n",
      "Average validation loss: 0.03520727579016238\n",
      "160/160 [==============================] - 128s 798ms/step - loss: 9.3203e-05 - val_loss: 0.0352\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 254s 789ms/step - loss: 8.9278e-05 - val_loss: 0.0352\n",
      "Average validation loss: 0.13162554380251096\n",
      "160/160 [==============================] - 256s 799ms/step - loss: 8.9278e-05 - val_loss: 0.0834\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 381s 785ms/step - loss: 8.9635e-05 - val_loss: 0.0834\n",
      "Average validation loss: 0.03109664055518806\n",
      "160/160 [==============================] - 383s 797ms/step - loss: 8.9635e-05 - val_loss: 0.0660\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 510s 792ms/step - loss: 8.7812e-05 - val_loss: 0.0660\n",
      "Average validation loss: 0.031051803287118672\n",
      "160/160 [==============================] - 512s 803ms/step - loss: 8.7812e-05 - val_loss: 0.0572\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 639s 796ms/step - loss: 8.5919e-05 - val_loss: 0.0572\n",
      "Average validation loss: 0.030844284198246898\n",
      "160/160 [==============================] - 641s 808ms/step - loss: 8.5919e-05 - val_loss: 0.0520\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 767s 790ms/step - loss: 8.5187e-05 - val_loss: 0.0520\n",
      "Average validation loss: 0.1475727426019148\n",
      "160/160 [==============================] - 769s 801ms/step - loss: 8.5187e-05 - val_loss: 0.0679\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 895s 788ms/step - loss: 8.4725e-05 - val_loss: 0.0679\n",
      "Average validation loss: 0.03845240757800639\n",
      "160/160 [==============================] - 897s 799ms/step - loss: 8.4725e-05 - val_loss: 0.0637\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1024s 791ms/step - loss: 8.3812e-05 - val_loss: 0.0637\n",
      "Average validation loss: 0.046562665281817316\n",
      "160/160 [==============================] - 1025s 802ms/step - loss: 8.3812e-05 - val_loss: 0.0616\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1152s 789ms/step - loss: 8.3704e-05 - val_loss: 0.0616\n",
      "Average validation loss: 0.039854923635721205\n",
      "160/160 [==============================] - 1153s 800ms/step - loss: 8.3704e-05 - val_loss: 0.0591\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1280s 788ms/step - loss: 8.2443e-05 - val_loss: 0.0591\n",
      "Average validation loss: 0.09279845752753317\n",
      "160/160 [==============================] - 1281s 799ms/step - loss: 8.2443e-05 - val_loss: 0.0625\n",
      "Train loss: 8.244332829594914e-05, Validation loss: 0.06250667442582199\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 127s 792ms/step - loss: 7.1198e-05\n",
      "Average validation loss: 0.030717205174732955\n",
      "160/160 [==============================] - 128s 802ms/step - loss: 7.1198e-05 - val_loss: 0.0307\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 256s 794ms/step - loss: 6.9983e-05 - val_loss: 0.0307\n",
      "Average validation loss: 0.03516321403585607\n",
      "160/160 [==============================] - 257s 805ms/step - loss: 6.9983e-05 - val_loss: 0.0329\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 384s 791ms/step - loss: 6.8550e-05 - val_loss: 0.0329\n",
      "Average validation loss: 0.03770950206089765\n",
      "160/160 [==============================] - 386s 802ms/step - loss: 6.8550e-05 - val_loss: 0.0345\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 514s 798ms/step - loss: 6.6676e-05 - val_loss: 0.0345\n",
      "Average validation loss: 0.03511779060936533\n",
      "160/160 [==============================] - 515s 809ms/step - loss: 6.6676e-05 - val_loss: 0.0347\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 642s 792ms/step - loss: 6.6950e-05 - val_loss: 0.0347\n",
      "Average validation loss: 0.028234607352351303\n",
      "160/160 [==============================] - 644s 802ms/step - loss: 6.6950e-05 - val_loss: 0.0334\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 771s 792ms/step - loss: 6.5151e-05 - val_loss: 0.0334\n",
      "Average validation loss: 0.0340149863739498\n",
      "160/160 [==============================] - 772s 802ms/step - loss: 6.5151e-05 - val_loss: 0.0335\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 899s 791ms/step - loss: 6.3660e-05 - val_loss: 0.0335\n",
      "Average validation loss: 0.03031856724410318\n",
      "160/160 [==============================] - 901s 802ms/step - loss: 6.3660e-05 - val_loss: 0.0330\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1027s 790ms/step - loss: 6.2114e-05 - val_loss: 0.0330\n",
      "Average validation loss: 0.05216915800701827\n",
      "160/160 [==============================] - 1029s 801ms/step - loss: 6.2114e-05 - val_loss: 0.0354\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1157s 798ms/step - loss: 6.0417e-05 - val_loss: 0.0354\n",
      "Average validation loss: 0.4165187019854784\n",
      "160/160 [==============================] - 1159s 809ms/step - loss: 6.0417e-05 - val_loss: 0.0778\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1286s 795ms/step - loss: 6.0089e-05 - val_loss: 0.0778\n",
      "Average validation loss: 0.05452954538632184\n",
      "160/160 [==============================] - 1288s 806ms/step - loss: 6.0089e-05 - val_loss: 0.0754\n",
      "Train loss: 6.0089247651096306e-05, Validation loss: 0.07544932782300748\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 127s 791ms/step - loss: 6.0944e-05\n",
      "Average validation loss: 0.046651839395053685\n",
      "160/160 [==============================] - 128s 802ms/step - loss: 6.0944e-05 - val_loss: 0.0467\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 255s 791ms/step - loss: 5.8078e-05 - val_loss: 0.0467\n",
      "Average validation loss: 0.027237808576319366\n",
      "160/160 [==============================] - 257s 802ms/step - loss: 5.8078e-05 - val_loss: 0.0369\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 383s 790ms/step - loss: 5.7277e-05 - val_loss: 0.0369\n",
      "Average validation loss: 0.05720847268239595\n",
      "160/160 [==============================] - 385s 800ms/step - loss: 5.7277e-05 - val_loss: 0.0437\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 512s 794ms/step - loss: 5.6178e-05 - val_loss: 0.0437\n",
      "Average validation loss: 0.022780408442486078\n",
      "160/160 [==============================] - 514s 805ms/step - loss: 5.6178e-05 - val_loss: 0.0385\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 641s 796ms/step - loss: 6.0063e-05 - val_loss: 0.0385\n",
      "Average validation loss: 0.04334533088840544\n",
      "160/160 [==============================] - 643s 807ms/step - loss: 6.0063e-05 - val_loss: 0.0394\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 763s 748ms/step - loss: 5.9298e-05 - val_loss: 0.0394\n",
      "Average validation loss: 0.02380669335834682\n",
      "160/160 [==============================] - 764s 758ms/step - loss: 5.9298e-05 - val_loss: 0.0368\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 877s 706ms/step - loss: 5.8560e-05 - val_loss: 0.0368\n",
      "Average validation loss: 0.053389613050967455\n",
      "160/160 [==============================] - 879s 716ms/step - loss: 5.8560e-05 - val_loss: 0.0392\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 992s 706ms/step - loss: 5.6603e-05 - val_loss: 0.0392\n",
      "Average validation loss: 0.021639791456982492\n",
      "160/160 [==============================] - 993s 716ms/step - loss: 5.6603e-05 - val_loss: 0.0370\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_200.pth'.\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1106s 707ms/step - loss: 5.4318e-05 - val_loss: 0.0370\n",
      "Average validation loss: 0.03835372468456626\n",
      "160/160 [==============================] - 1108s 717ms/step - loss: 5.4318e-05 - val_loss: 0.0372\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1222s 709ms/step - loss: 5.3748e-05 - val_loss: 0.0372\n",
      "Average validation loss: 0.06434764773584903\n",
      "160/160 [==============================] - 1223s 719ms/step - loss: 5.3748e-05 - val_loss: 0.0399\n",
      "Train loss: 5.3748421257951876e-05, Validation loss: 0.03987613302713726\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/240 [..............................] - ETA: 2:44 - loss: 8.6382e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\sam_trial\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 171s 713ms/step - loss: 8.2458e-05\n",
      "Average validation loss: 0.034419179420607786\n",
      "240/240 [==============================] - 174s 724ms/step - loss: 8.2458e-05 - val_loss: 0.0344\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 344s 710ms/step - loss: 7.0605e-05 - val_loss: 0.0344\n",
      "Average validation loss: 0.02994041925218577\n",
      "240/240 [==============================] - 346s 720ms/step - loss: 7.0605e-05 - val_loss: 0.0322\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 516s 709ms/step - loss: 6.5665e-05 - val_loss: 0.0322\n",
      "Average validation loss: 0.03328231170307845\n",
      "240/240 [==============================] - 519s 718ms/step - loss: 6.5665e-05 - val_loss: 0.0325\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 690s 712ms/step - loss: 6.1969e-05 - val_loss: 0.0325\n",
      "Average validation loss: 0.03190599169271688\n",
      "240/240 [==============================] - 692s 722ms/step - loss: 6.1969e-05 - val_loss: 0.0324\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 863s 712ms/step - loss: 5.8987e-05 - val_loss: 0.0324\n",
      "Average validation loss: 0.03860331244650297\n",
      "240/240 [==============================] - 865s 722ms/step - loss: 5.8987e-05 - val_loss: 0.0336\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1035s 706ms/step - loss: 5.6783e-05 - val_loss: 0.0336\n",
      "Average validation loss: 0.064135591344287\n",
      "240/240 [==============================] - 1037s 716ms/step - loss: 5.6783e-05 - val_loss: 0.0387\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1207s 708ms/step - loss: 5.5178e-05 - val_loss: 0.0387\n",
      "Average validation loss: 0.03139211943683525\n",
      "240/240 [==============================] - 1210s 718ms/step - loss: 5.5178e-05 - val_loss: 0.0377\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1379s 706ms/step - loss: 5.2268e-05 - val_loss: 0.0377\n",
      "Average validation loss: 0.029468448467863104\n",
      "240/240 [==============================] - 1382s 716ms/step - loss: 5.2268e-05 - val_loss: 0.0366\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1552s 708ms/step - loss: 5.1703e-05 - val_loss: 0.0366\n",
      "Average validation loss: 0.0750473218349119\n",
      "240/240 [==============================] - 1554s 718ms/step - loss: 5.1703e-05 - val_loss: 0.0409\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1724s 710ms/step - loss: 5.0398e-05 - val_loss: 0.0409\n",
      "Average validation loss: 0.042476550800104936\n",
      "240/240 [==============================] - 1727s 720ms/step - loss: 5.0398e-05 - val_loss: 0.0411\n",
      "Train loss: 5.0397981894679305e-05, Validation loss: 0.0410671246399094\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 170s 707ms/step - loss: 5.9276e-05\n",
      "Average validation loss: 0.023077900882344692\n",
      "240/240 [==============================] - 172s 717ms/step - loss: 5.9276e-05 - val_loss: 0.0231\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 342s 708ms/step - loss: 4.8445e-05 - val_loss: 0.0231\n",
      "Average validation loss: 0.020393903095585603\n",
      "240/240 [==============================] - 344s 717ms/step - loss: 4.8445e-05 - val_loss: 0.0217\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 514s 707ms/step - loss: 4.5735e-05 - val_loss: 0.0217\n",
      "Average validation loss: 0.043138250972454745\n",
      "240/240 [==============================] - 516s 717ms/step - loss: 4.5735e-05 - val_loss: 0.0289\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 686s 708ms/step - loss: 5.1115e-05 - val_loss: 0.0289\n",
      "Average validation loss: 0.025652805504311496\n",
      "240/240 [==============================] - 689s 718ms/step - loss: 5.1115e-05 - val_loss: 0.0281\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 858s 705ms/step - loss: 4.7957e-05 - val_loss: 0.0281\n",
      "Average validation loss: 0.02046529430857239\n",
      "240/240 [==============================] - 860s 715ms/step - loss: 4.7957e-05 - val_loss: 0.0265\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1030s 709ms/step - loss: 4.5032e-05 - val_loss: 0.0265\n",
      "Average validation loss: 0.029128628079221622\n",
      "240/240 [==============================] - 1033s 718ms/step - loss: 4.5032e-05 - val_loss: 0.0270\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1204s 712ms/step - loss: 4.3339e-05 - val_loss: 0.0270\n",
      "Average validation loss: 0.02146213156132338\n",
      "240/240 [==============================] - 1206s 722ms/step - loss: 4.3339e-05 - val_loss: 0.0262\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1376s 710ms/step - loss: 4.3535e-05 - val_loss: 0.0262\n",
      "Average validation loss: 0.11102077499769318\n",
      "240/240 [==============================] - 1379s 720ms/step - loss: 4.3535e-05 - val_loss: 0.0368\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1548s 707ms/step - loss: 5.2109e-05 - val_loss: 0.0368\n",
      "Average validation loss: 0.035497304804933565\n",
      "240/240 [==============================] - 1551s 717ms/step - loss: 5.2109e-05 - val_loss: 0.0366\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1720s 705ms/step - loss: 5.1483e-05 - val_loss: 0.0366\n",
      "Average validation loss: 0.04230603743344545\n",
      "240/240 [==============================] - 1722s 715ms/step - loss: 5.1483e-05 - val_loss: 0.0372\n",
      "Train loss: 5.148303463299015e-05, Validation loss: 0.03721430316398862\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 170s 709ms/step - loss: 4.3974e-05\n",
      "Average validation loss: 0.0753431713518997\n",
      "240/240 [==============================] - 172s 719ms/step - loss: 4.3974e-05 - val_loss: 0.0753\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 343s 712ms/step - loss: 4.4405e-05 - val_loss: 0.0753\n",
      "Average validation loss: 0.1561906397342682\n",
      "240/240 [==============================] - 346s 722ms/step - loss: 4.4405e-05 - val_loss: 0.1158\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 516s 711ms/step - loss: 4.1123e-05 - val_loss: 0.1158\n",
      "Average validation loss: 0.024897321513465916\n",
      "240/240 [==============================] - 519s 721ms/step - loss: 4.1123e-05 - val_loss: 0.0855\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 688s 705ms/step - loss: 3.8031e-05 - val_loss: 0.0855\n",
      "Average validation loss: 0.14996266377468903\n",
      "240/240 [==============================] - 690s 715ms/step - loss: 3.8031e-05 - val_loss: 0.1016\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 860s 706ms/step - loss: 4.4039e-05 - val_loss: 0.1016\n",
      "Average validation loss: 0.028520307223273752\n",
      "240/240 [==============================] - 862s 715ms/step - loss: 4.4039e-05 - val_loss: 0.0870\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1032s 710ms/step - loss: 4.4374e-05 - val_loss: 0.0870\n",
      "Average validation loss: 0.028505170694552363\n",
      "240/240 [==============================] - 1035s 720ms/step - loss: 4.4374e-05 - val_loss: 0.0772\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1205s 708ms/step - loss: 4.2613e-05 - val_loss: 0.0772\n",
      "Average validation loss: 0.026830229597787063\n",
      "240/240 [==============================] - 1207s 718ms/step - loss: 4.2613e-05 - val_loss: 0.0700\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1377s 708ms/step - loss: 4.0174e-05 - val_loss: 0.0700\n",
      "Average validation loss: 0.02587307533249259\n",
      "240/240 [==============================] - 1380s 718ms/step - loss: 4.0174e-05 - val_loss: 0.0645\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1549s 708ms/step - loss: 3.8344e-05 - val_loss: 0.0645\n",
      "Average validation loss: 0.02048162668167303\n",
      "240/240 [==============================] - 1552s 718ms/step - loss: 3.8344e-05 - val_loss: 0.0596\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1722s 708ms/step - loss: 3.6510e-05 - val_loss: 0.0596\n",
      "Average validation loss: 0.05812970938471456\n",
      "240/240 [==============================] - 1724s 718ms/step - loss: 3.6510e-05 - val_loss: 0.0595\n",
      "Train loss: 3.651029671912976e-05, Validation loss: 0.05947339152888161\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 169s 705ms/step - loss: 3.3084e-05\n",
      "Average validation loss: 0.036236429161666216\n",
      "240/240 [==============================] - 172s 715ms/step - loss: 3.3084e-05 - val_loss: 0.0362\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 341s 706ms/step - loss: 3.1004e-05 - val_loss: 0.0362\n",
      "Average validation loss: 0.05610785574999681\n",
      "240/240 [==============================] - 343s 716ms/step - loss: 3.1004e-05 - val_loss: 0.0462\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 513s 706ms/step - loss: 3.5400e-05 - val_loss: 0.0462\n",
      "Average validation loss: 0.08476519963393608\n",
      "240/240 [==============================] - 515s 716ms/step - loss: 3.5400e-05 - val_loss: 0.0590\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 685s 708ms/step - loss: 3.5179e-05 - val_loss: 0.0590\n",
      "Average validation loss: 0.4353633498152097\n",
      "240/240 [==============================] - 688s 718ms/step - loss: 3.5179e-05 - val_loss: 0.1531\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 857s 706ms/step - loss: 3.3468e-05 - val_loss: 0.1531\n",
      "Average validation loss: 0.10679905017217001\n",
      "240/240 [==============================] - 859s 716ms/step - loss: 3.3468e-05 - val_loss: 0.1439\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1033s 723ms/step - loss: 3.1001e-05 - val_loss: 0.1439\n",
      "Average validation loss: 0.046482454872845365\n",
      "240/240 [==============================] - 1035s 733ms/step - loss: 3.1001e-05 - val_loss: 0.1276\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1206s 709ms/step - loss: 3.0765e-05 - val_loss: 0.1276\n",
      "Average validation loss: 0.04468892271834193\n",
      "240/240 [==============================] - 1208s 719ms/step - loss: 3.0765e-05 - val_loss: 0.1158\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1378s 708ms/step - loss: 3.0235e-05 - val_loss: 0.1158\n",
      "Average validation loss: 0.01977295261264468\n",
      "240/240 [==============================] - 1380s 718ms/step - loss: 3.0235e-05 - val_loss: 0.1038\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1562s 757ms/step - loss: 2.9057e-05 - val_loss: 0.1038\n",
      "Average validation loss: 0.018075174102947737\n",
      "240/240 [==============================] - 1564s 766ms/step - loss: 2.9057e-05 - val_loss: 0.0943\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1748s 767ms/step - loss: 2.7982e-05 - val_loss: 0.0943\n",
      "Average validation loss: 0.1495540041476488\n",
      "240/240 [==============================] - 1751s 778ms/step - loss: 2.7982e-05 - val_loss: 0.0998\n",
      "Train loss: 2.79820659957921e-05, Validation loss: 0.09978453929874073\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "cuda : NVIDIA GeForce RTX 4090\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 172s 715ms/step - loss: 2.6955e-05\n",
      "Average validation loss: 0.09296831842511892\n",
      "240/240 [==============================] - 174s 725ms/step - loss: 2.6955e-05 - val_loss: 0.0930\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 343s 704ms/step - loss: 2.5487e-05 - val_loss: 0.0930\n",
      "Average validation loss: 0.021611900154190757\n",
      "240/240 [==============================] - 345s 714ms/step - loss: 2.5487e-05 - val_loss: 0.0573\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 515s 706ms/step - loss: 2.4242e-05 - val_loss: 0.0573\n",
      "Average validation loss: 0.019972647082371016\n",
      "240/240 [==============================] - 517s 715ms/step - loss: 2.4242e-05 - val_loss: 0.0449\n",
      "Saved model weights to 'c:\\Users\\user\\Desktop\\天_11157065\\git\\RipplesDetection\\ar2DB\\weights/weights_KD_segformer_0628/weights_KD_segformer_0628_20\\segformer_data_size_300.pth'.\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 687s 706ms/step - loss: 2.3137e-05 - val_loss: 0.0449\n",
      "Average validation loss: 0.035156113328412175\n",
      "240/240 [==============================] - 689s 716ms/step - loss: 2.3137e-05 - val_loss: 0.0424\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 859s 710ms/step - loss: 2.3587e-05 - val_loss: 0.0424\n",
      "Average validation loss: 0.045471203552248575\n",
      "240/240 [==============================] - 862s 719ms/step - loss: 2.3587e-05 - val_loss: 0.0430\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 1031s 707ms/step - loss: 2.3581e-05 - val_loss: 0.0430\n",
      "Average validation loss: 0.02471845873321096\n",
      "240/240 [==============================] - 1034s 717ms/step - loss: 2.3581e-05 - val_loss: 0.0400\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 1203s 705ms/step - loss: 2.3213e-05 - val_loss: 0.0400\n",
      "Average validation loss: 0.03536856085217247\n",
      "240/240 [==============================] - 1205s 715ms/step - loss: 2.3213e-05 - val_loss: 0.0393\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 1375s 706ms/step - loss: 2.4137e-05 - val_loss: 0.0393\n",
      "Average validation loss: 0.08979053571820259\n",
      "240/240 [==============================] - 1377s 716ms/step - loss: 2.4137e-05 - val_loss: 0.0456\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 1546s 705ms/step - loss: 2.3914e-05 - val_loss: 0.0456\n",
      "Average validation loss: 0.03560309434930484\n",
      "240/240 [==============================] - 1549s 715ms/step - loss: 2.3914e-05 - val_loss: 0.0445\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 1719s 707ms/step - loss: 2.3323e-05 - val_loss: 0.0445\n",
      "Average validation loss: 0.023084639466833323\n",
      "240/240 [==============================] - 1721s 717ms/step - loss: 2.3323e-05 - val_loss: 0.0424\n",
      "Train loss: 2.3323306811332322e-05, Validation loss: 0.04237454716620656\n",
      "CPU times: total: 5h 48min 38s\n",
      "Wall time: 5h 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig, SegformerImageProcessor\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import SamModel, SamProcessor\n",
    "from torch import nn\n",
    "from scipy.ndimage import label, find_objects\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datetime import datetime\n",
    "\n",
    "# DataSet\n",
    "class SplashDataSet_train_val_0501(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.images_dir = os.path.join(self.root_dir, \"images\")\n",
    "        self.masks_dir = os.path.join(self.root_dir, \"annotations\")\n",
    "        # get filenames\n",
    "        self.images_list = sorted(os.listdir(self.images_dir))\n",
    "        self.masks_list = sorted(os.listdir(self.masks_dir))\n",
    "        assert len(self.images_list) == len(self.masks_list), \"Number of images and annotations should be the same.\"\n",
    "\n",
    "        # transform image to 1024*1024\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((1024, 1024)),\n",
    "            transforms.ToTensor(),  # This will scale pixel values to [0, 1]\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get image and annotation file\n",
    "        img_path = os.path.join(self.images_dir, self.images_list[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks_list[idx])\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        # Convert mask to binary 0 and 1\n",
    "        mask = (mask > 0).to(torch.int)\n",
    "        mask = mask[0, None, :, :]\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "    def get_time_category(self, filename):\n",
    "        # my filenames' format is 2024-04-09-03-00-11.png\n",
    "        time_str = filename.split('-')[3:5]\n",
    "        time_obj = datetime.strptime('-'.join(time_str), '%H-%M')\n",
    "        hour = time_obj.hour\n",
    "        if hour < 8:\n",
    "            return 'morning'\n",
    "        elif 8 <= hour <= 16:\n",
    "            return 'day'\n",
    "        else:\n",
    "            return 'evening'\n",
    "\n",
    "def focal_loss(inputs, targets, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "    #print(\"inputs size = \", inputs.size())\n",
    "    # inputs size =  torch.Size([1, 2, 1024, 1024])\n",
    "    #print(\"targets size = \", targets.size())\n",
    "    # targets size =  torch.Size([1, 1024, 1024])\n",
    "    BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "    targets = targets.type(torch.float32)\n",
    "    at = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "    pt = torch.exp(-BCE_loss)\n",
    "    F_loss = at * (1 - pt)**gamma * BCE_loss\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(F_loss), (1 - pt)**gamma\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(F_loss)\n",
    "    else:\n",
    "        return F_loss\n",
    "\n",
    "# criterion\n",
    "def criterion(outputs, labels):\n",
    "    return torch.nn.functional.cross_entropy(outputs, labels.squeeze(1).long())\n",
    "\n",
    "def KD_criterion(student_outputs, teacher_outputs, labels, teacher_ratio, temperature):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    #print(\"student_outputs size = \", student_outputs.size())\n",
    "    # print(\"student_outputs = \", student_outputs[\"out\"])\n",
    "    #print(\"teacher_outputs size = \", teacher_outputs.size())\n",
    "    # print(\"teacher_outputs = \", teacher_outputs)\n",
    "    #print(\"ground truth size = \", labels.size())\n",
    "    \n",
    "    # Calculate Cross Entropy\n",
    "    # original_loss = torch.nn.functional.cross_entropy(student_outputs, labels.squeeze(1).long())\n",
    "\n",
    "    # Calculate Focal Loss , not sure about alpha and gamme\n",
    "    #original_loss = focal_loss(student_outputs[:,1,:,:], labels.squeeze(1).float(), alpha=0.25, gamma=2.0)\n",
    "    alpha=0.25\n",
    "    gamma=2.0\n",
    "    targets = labels.squeeze(1).float()\n",
    "    BCE_loss = F.binary_cross_entropy_with_logits(student_outputs[:,1,:,:], targets, reduction='none')\n",
    "    targets = targets.type(torch.float32)\n",
    "    at = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "    pt = torch.exp(-BCE_loss)\n",
    "    modulating_number = torch.mean((1 - pt)**gamma)\n",
    "    F_loss = at * modulating_number * BCE_loss\n",
    "    #print(\"modulating_number = \", modulating_number)\n",
    "    # mean\n",
    "    original_loss = torch.mean(F_loss)\n",
    "    #print(\"original loss = \", original_loss)\n",
    "\n",
    "    # Calculate Distillation Loss\n",
    "    soft_teacher_outputs = torch.softmax(teacher_outputs[0, 0, :, :] / temperature, dim=1)\n",
    "    soft_student_outputs = torch.log_softmax(student_outputs[0, 0, :, :] / temperature, dim=1)\n",
    "    distillation_loss = nn.KLDivLoss()(soft_student_outputs.to(device), soft_teacher_outputs.to(device))\n",
    "    #print(\"distillation loss = \", distillation_loss)\n",
    "    \n",
    "    # total loss\n",
    "    #total_loss = modulating_number*((1-teacher_ratio)*original_loss + teacher_ratio*distillation_loss)\n",
    "    total_loss = (1-teacher_ratio)*original_loss + teacher_ratio*distillation_loss*modulating_number\n",
    "    return total_loss\n",
    "\n",
    "# evaluate\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for image, mask in val_loader:\n",
    "            image, mask = image.to(device), mask.to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "\n",
    "            loss = criterion(outputs['out'], mask)\n",
    "\n",
    "            # Calculate Focal Loss , not sure about alpha and gamme\n",
    "            #print(\"outputs size = \", outputs['out'].size())\n",
    "            #print(\"mask size = \", mask.size())\n",
    "            # outputs['out'] size =  torch.Size([1, 2, 1024, 1024])\n",
    "            # mask size =  torch.Size([1, 1, 1024, 1024])\n",
    "            #loss = focal_loss(outputs['out'][:,1:2,:,:], mask.float())\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    print(f\"Average validation loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "# train every epoch\n",
    "def train_one_epoch(student_model, teacher_model, teacher_image_processor, data_loader, teacher_ratio, temperature, optimizer, device, pbar):\n",
    "    student_model.to(device)\n",
    "    student_model.train()\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    training_loss = []\n",
    "    for idx, (image, mask) in enumerate(data_loader):\n",
    "        #bbox = [[[get_bounding_box(np.array(mask))]]]\n",
    "        bbox, point = get_bounding_box_and_center(np.array(mask))\n",
    "        #print(\"[train_one_epoch] bbox = \", bbox)\n",
    "        #print(\"[train_one_epoch] point = \", point)\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        # image size = torch.Size([1, 3, 1024, 1024])start_step\n",
    "        # mask size = torch.Size([1, 1, 1024, 1024])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # output for student model ----------------------------------------------------------\n",
    "        student_outputs = student_model(image)\n",
    "        # outputs size = torch.Size([1, 2, 1024, 1024])\n",
    "        # -----------------------------------------------------------------------------------\n",
    "        # output for teacher model ----------------------------------------------------------\n",
    "        # Retrieve the image embeddings\n",
    "        # processor\n",
    "        teacher_inputs = teacher_image_processor(image, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "        teacher_image_embeddings = teacher_model.get_image_embeddings(teacher_inputs[\"pixel_values\"])\n",
    "        \n",
    "        # 送到processor計算遮罩\n",
    "        if bbox is None:\n",
    "            teacher_inputs = teacher_image_processor(image, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "        else:\n",
    "            teacher_inputs = teacher_image_processor(image, input_points=[[[point]]], input_boxes=[[[bbox]]], return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "\n",
    "        teacher_inputs.pop(\"pixel_values\", None)\n",
    "        teacher_inputs.update({\"image_embeddings\": teacher_image_embeddings})\n",
    "\n",
    "        teacher_outputs = teacher_model(**teacher_inputs)\n",
    "        teacher_masks, teacher_output = teacher_image_processor.image_processor.post_process_masks(teacher_outputs.pred_masks.cpu(), teacher_inputs[\"original_sizes\"].cpu(), teacher_inputs[\"reshaped_input_sizes\"].cpu())  \n",
    "        # -----------------------------------------------------------------------------------\n",
    "        #loss = criterion(student_outputs, mask)\n",
    "        loss = KD_criterion(student_outputs['out'], teacher_output[0], mask, teacher_ratio, temperature)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \"\"\"\n",
    "        [train_one_epoch] image size =  torch.Size([1, 3, 1024, 1024])\n",
    "        [train_one_epoch]0 mask size =  torch.Size([1, 1, 1024, 1024])\n",
    "        [train_one_epoch]0 outputs size =  torch.Size([1, 2, 128, 128])\n",
    "        [train_one_epoch]1 outputs size =  torch.Size([1, 2, 1024, 1024])\n",
    "        \"\"\"\n",
    "        training_loss.append(loss.item())\n",
    "        pbar.update(idx + 1, values=[(\"loss\", loss.item())])\n",
    "    return np.mean(np.array(training_loss))\n",
    "\n",
    "# train\n",
    "def train(model, teacher_model, teacher_image_processor, train_loader, val_loader, train_size, save_model, teacher_ratio=0.7, temperature=1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device, \":\",torch.cuda.get_device_name(0))\n",
    "\n",
    "    train_losses   = []\n",
    "    val_losses     = []\n",
    "    epochs = 10\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    n_batch = len(train_loader)\n",
    "    pbar = tf.keras.utils.Progbar(target=n_batch, stateful_metrics=None)\n",
    "    ######### weight\n",
    "    # 動態生成儲存模型權重的檔名，加入目前使用的資料集大小的數字\n",
    "    weight_filename = f\"segformer_data_size_{train_size}.pth\"\n",
    "    # 確定weights資料夾是否存在，如果不存在則新增它\n",
    "    #weights_dir = os.path.join(os.getcwd(),\"weights\")\n",
    "    weights_dir = os.path.join(os.getcwd(), f\"weights/weights_KD_segformer_0628/weights_KD_segformer_0628_{int(teacher_ratio*100)}\")\n",
    "    if not os.path.exists(weights_dir):\n",
    "        os.makedirs(weights_dir)\n",
    "    model_pathname = os.path.join(weights_dir, weight_filename)\n",
    "    ######### weight end\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, teacher_model, teacher_image_processor, train_loader, teacher_ratio, temperature, optimizer, device, pbar)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_loss = evaluate(model, val_loader, device)\n",
    "            val_losses.append(val_loss)\n",
    "            pbar.update(n_batch, values=[('val_loss', val_loss)])\n",
    "\n",
    "            if val_loss < best_val_loss and save_model:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), model_pathname)\n",
    "                print(f\"Saved model weights to '{model_pathname}'.\")\n",
    "    print(f\"Train loss: {np.mean(train_losses)}, Validation loss: {np.mean(val_losses)}\" if val_loader is not None else f\"Train loss: {np.mean(train_losses)}\")\n",
    "    return {'loss':train_losses, 'val_loss':val_losses}\n",
    "\n",
    "def select_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    parent_folder = filedialog.askdirectory(title=\"選擇資料夾\")\n",
    "    return parent_folder\n",
    "\n",
    "def get_bounding_box(ground_truth_map):\n",
    "  ground_truth_map = ground_truth_map[0, 0, :, :]\n",
    "  #print(\"ground_truth_map = \", ground_truth_map.shape)\n",
    "  # get bounding box from mask\n",
    "  y_indices, x_indices = np.where(ground_truth_map > 0)\n",
    "  x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "  y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "  # add perturbation to bounding box coordinates\n",
    "  H, W = ground_truth_map.shape\n",
    "  x_min = max(0, x_min - np.random.randint(0, 20))\n",
    "  x_max = min(W, x_max + np.random.randint(0, 20))\n",
    "  y_min = max(0, y_min - np.random.randint(0, 20))\n",
    "  y_max = min(H, y_max + np.random.randint(0, 20))\n",
    "  bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "  return bbox\n",
    "\n",
    "def get_bounding_box_and_center(ground_truth_map):\n",
    "    #print(\"[get_bounding_box_and_center]\")\n",
    "    ground_truth_map = ground_truth_map[0, 0, :, :]\n",
    "    if np.any(ground_truth_map > 0):\n",
    "        # get bounding box from mask\n",
    "        y_indices, x_indices = np.where(ground_truth_map > 0)\n",
    "        x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "        y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "        # add perturbation to bounding box coordinates\n",
    "        H, W = ground_truth_map.shape\n",
    "        x_min = max(0, x_min - np.random.randint(0, 20))\n",
    "        x_max = min(W, x_max + np.random.randint(0, 20))\n",
    "        y_min = max(0, y_min - np.random.randint(0, 20))\n",
    "        y_max = min(H, y_max + np.random.randint(0, 20))\n",
    "        bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "        # Identify the largest connected component (largest mask area)\n",
    "        labeled_array, num_features = label(ground_truth_map > 0)\n",
    "        if num_features > 0:\n",
    "            # Find the largest component\n",
    "            max_label = 1 + np.argmax([np.sum(labeled_array == i) for i in range(1, num_features+1)])\n",
    "            # Get the slice for the largest component\n",
    "            largest_component_slice = find_objects(labeled_array == max_label)[0]\n",
    "            yc, xc = largest_component_slice\n",
    "            center_x = xc.start + (xc.stop - xc.start) // 2\n",
    "            center_y = yc.start + (yc.stop - yc.start) // 2\n",
    "            center_point = (center_x, center_y)\n",
    "        else:\n",
    "            center_point = ((x_min + x_max) // 2, (y_min + y_max) // 2)\n",
    "    else:\n",
    "        bbox = None\n",
    "        center_point = None\n",
    "    return bbox, center_point\n",
    "\n",
    "class MySegFormer_0628(nn.Module):\n",
    "    def __init__(self,num_classes,backbone=\"b0\",id2label=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if id2label is not None:\n",
    "            self.id2label = id2label\n",
    "        else:\n",
    "            self.id2label = {i:str(i) for i in range(self.num_classes)}\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(f\"nvidia/mit-{backbone}\",\n",
    "                                                         num_labels=self.num_classes, \n",
    "                                                         id2label=self.id2label, \n",
    "                                                         label2id={v:k for k,v in self.id2label.items()}\n",
    "                                                         , ignore_mismatched_sizes=True)\n",
    "    def forward(self,x):\n",
    "        y = self.segformer(x)\n",
    "        y = nn.functional.interpolate(y.logits, size=x.shape[-2:], mode=\"bilinear\", align_corners=False,antialias=True)        \n",
    "        return {'out':y}\n",
    "        # 在conda 環境裡huggingface包好的Segformer有改(modeling_segformer.py)\n",
    "\n",
    "# Student Model: Segformer 0601\n",
    "backbone = \"b0\"\n",
    "num_classes = 2\n",
    "model_segformer = MySegFormer_0628(num_classes, backbone)\n",
    "\n",
    "# Teacher Model: Segment Anything Model\n",
    "model_sam = SamModel.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "processor_sam = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "\n",
    "train_sizes = [5, 10, 100, 200, 300]\n",
    "#train_sizes = [300]\n",
    "# 放所有 fold 的 平均、標準差\n",
    "mean_val_losses = []\n",
    "std_val_losses = []\n",
    "root_dir = select_folder()\n",
    "\n",
    "#root_dir = \"C:/Users/user/Desktop/NAS_data/鱸魚/高雄黃明和/train_0418\"\n",
    "#print(root_dir)\n",
    "\n",
    "# My DataSet, return image, mask\n",
    "train_val_dataset = SplashDataSet_train_val_0501(root_dir=root_dir)\n",
    "labels = [train_val_dataset.get_time_category(filename) for filename in train_val_dataset.images_list]\n",
    "#print(\"indices 1= \", indices)\n",
    "#print(\"label size = \", label.size())\n",
    "#print(\"label = \", len(labels))\n",
    "#print(\"len(train_val_dataset = )\", len(train_val_dataset))\n",
    "for train_size in train_sizes:\n",
    "    # 在前一個大小的資料袋中擴增資料(train+validation)\n",
    "    indices = np.arange(len(train_val_dataset))\n",
    "    indices = indices[:train_size]\n",
    "    # print(\"indices = \", indices)\n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    val_losses = []  # 放每個 fold 的 validation loss\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(indices, [labels[i] for i in indices])):\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "        train_idx = indices[train_idx]\n",
    "        val_idx = indices[val_idx]\n",
    "        \"\"\"\n",
    "        for i in indices:\n",
    "            print(\"i = \", i)\n",
    "            print(\"labels[i] = \", labels[i])\n",
    "        print(\"----\")\n",
    "        \"\"\"\n",
    "        \n",
    "        train_subset = Subset(train_val_dataset, train_idx)\n",
    "        val_subset = Subset(train_val_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=1, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=1, shuffle=False)\n",
    "        # train\n",
    "        # Please replace Diatillation_Loss_Ratio to the teacher_ratio from 0 ~ 1 \n",
    "        teacher_ratio = 0.2\n",
    "        temperature = 5\n",
    "        lc = train(model_segformer, model_sam, processor_sam, train_loader, val_loader, train_size, True, teacher_ratio, temperature)\n",
    "\n",
    "        val_loss = lc['val_loss']\n",
    "        val_losses.append(val_loss)\n",
    "    mean_val_losses.append(np.mean(val_losses))\n",
    "    std_val_losses.append(np.std(val_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size size =  5\n",
      "mean_val_losses size =  5\n",
      "std_val_losses size =  5\n",
      "train_size =  [5, 10, 100, 200, 300]\n",
      "mean_val_losses =  [0.10079427947055168, 0.11503812056312343, 0.15067961244506806, 0.06006060525731301, 0.05598278115954538]\n",
      "std_val_losses =  [0.1607166093591868, 0.11590333304588635, 0.12847324396681445, 0.059090665862592526, 0.0643949225078403]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "print(\"train_size size = \", np.array(train_sizes).size)\n",
    "print(\"mean_val_losses size = \", np.array(mean_val_losses).size)\n",
    "print(\"std_val_losses size = \", np.array(std_val_losses).size)\n",
    "print(\"train_size = \", train_sizes)\n",
    "print(\"mean_val_losses = \", mean_val_losses)\n",
    "print(\"std_val_losses = \", std_val_losses)\n",
    "\n",
    "results_dir = os.path.join(os.getcwd(), 'TrainingRecords', 'results_KD_segformer_0628')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "results = {\n",
    "    \"train_sizes\": train_sizes,\n",
    "    \"mean_val_losses\": mean_val_losses,\n",
    "    \"std_val_losses\": std_val_losses\n",
    "}\n",
    "json_path = os.path.join(results_dir, f\"results_KD_segformer_0628_{int(teacher_ratio*100)}.json\")\n",
    "with open(json_path, 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, mean_val_losses, marker='o', color='black', label=f'distillation_loss_ratio={teacher_ratio}, original_loss_ratio={round(1-teacher_ratio, 2)}')\n",
    "plt.fill_between(train_sizes, np.maximum(0, np.array(mean_val_losses) - np.array(std_val_losses)), \n",
    "                 np.array(mean_val_losses) + np.array(std_val_losses), color='black', alpha=0.3)\n",
    "plt.title('Segformer B0')\n",
    "plt.xlabel('Dataset Size')\n",
    "plt.ylabel('Cross_Entropy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(results_dir, f\"results_KD_segformer_0628_{int(teacher_ratio*100)}.png\"))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam_trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
