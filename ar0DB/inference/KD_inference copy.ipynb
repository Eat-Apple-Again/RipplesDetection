{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig, SegformerImageProcessor\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import SamModel, SamProcessor\n",
    "from torch import nn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySegFormer_0409(nn.Module):\n",
    "    def __init__(self,num_classes,backbone=\"b1\",id2label=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if id2label is not None:\n",
    "            self.id2label = id2label\n",
    "        else:\n",
    "            self.id2label = {i:str(i) for i in range(self.num_classes)}\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(f\"nvidia/mit-{backbone}\",\n",
    "                                                         num_labels=self.num_classes, \n",
    "                                                         id2label=self.id2label, \n",
    "                                                         label2id={v:k for k,v in self.id2label.items()}\n",
    "                                                         , ignore_mismatched_sizes=True)\n",
    "    def forward(self,x):\n",
    "        y = self.segformer(x)\n",
    "        y = nn.functional.interpolate(y.logits, size=x.shape[-2:], mode=\"bilinear\", align_corners=False,antialias=True)        \n",
    "        return {'out':y}\n",
    "    \n",
    "class MySegFormer_0604(nn.Module):\n",
    "    def __init__(self,num_classes,backbone=\"b0\",id2label=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if id2label is not None:\n",
    "            self.id2label = id2label\n",
    "        else:\n",
    "            self.id2label = {i:str(i) for i in range(self.num_classes)}\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(f\"nvidia/mit-{backbone}\",\n",
    "                                                         num_labels=self.num_classes, \n",
    "                                                         id2label=self.id2label, \n",
    "                                                         label2id={v:k for k,v in self.id2label.items()}\n",
    "                                                         , ignore_mismatched_sizes=True)\n",
    "    def forward(self,x):\n",
    "        y = self.segformer(x)\n",
    "        y = nn.functional.interpolate(y.logits, size=x.shape[-2:], mode=\"bilinear\", align_corners=False,antialias=True)        \n",
    "        return {'out':y}\n",
    "        # 在conda 環境裡huggingface包好的Segformer有改(modeling_segformer.py)\n",
    "\n",
    "# Student Model: Segformer 0409\n",
    "model_name = \"nvidia/mit-b0\"\n",
    "num_classes = 2\n",
    "model_segformer = MySegFormer_0604(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import shutil\n",
    "\n",
    "#weight_dir = \"weights_KD_segformer_0418test_from0_60\\segformer_data_size_350.pth\"\n",
    "#weight_dir = \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/weights/weights_KD_segformer_0628/weights_KD_segformer_0628_30/segformer_data_size_300.pth\"\n",
    "weight_dir = \"C:/天_11157065/git/RipplesDetection/ar0DB/inference/segformer_data_size_300.pth\"\n",
    "#weight_dir = \"C:/天_11157065/git/RipplesDetection/ar0DB/inference/weight/weights_KD_segformer_0628_30/segformer_data_size_300.pth\"\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def transform_image(image):\n",
    "    try:\n",
    "        # Convert PIL Image to NumPy array\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        # Apply median blur using OpenCV\n",
    "        # image_np = cv2.medianBlur(image_np, 3)\n",
    "        \n",
    "        # Convert back to PIL Image\n",
    "        image = Image.fromarray(image_np)\n",
    "        # transform the image\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((1024, 1024)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        return transform(image)\n",
    "    except IOError as e:\n",
    "        print(f\"Error: - {e}\")\n",
    "        return None\n",
    "\n",
    "def select_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    parent_folder = filedialog.askdirectory(title=\"選擇影像資料夾\")\n",
    "    return parent_folder\n",
    "\n",
    "def apply_mask(mask, mask_path):\n",
    "    mask_image = Image.open(mask_path).convert('L')\n",
    "    mask_array = np.array(mask_image)\n",
    "    # 遮罩應用：將mask中被遮罩的部分設為0（背景類）\n",
    "    mask[mask_array == 0] = 0\n",
    "    return mask\n",
    "\n",
    "def move_png_files(data_dir_path):\n",
    "    raw_image_dir = os.path.join(data_dir_path, 'raw_image')\n",
    "    os.makedirs(raw_image_dir, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(data_dir_path):\n",
    "        if filename.endswith('.png'):\n",
    "            src = os.path.join(data_dir_path, filename)\n",
    "            dst = os.path.join(raw_image_dir, filename)\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "def KD_inference(model, weight_dir, data_dir_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.load_state_dict(torch.load(weight_dir, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    pixel_counts = []\n",
    "    image_dir_path = os.path.join(data_dir_path, 'raw_image')\n",
    "    os.makedirs(image_dir_path, exist_ok=True)\n",
    "\n",
    "    result_dir = os.path.join(data_dir_path, 'results')\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "    move_png_files(data_dir_path)\n",
    "\n",
    "    image_filename_list = sorted(os.listdir(image_dir_path))\n",
    "\n",
    "    magic_mask_path = \"magic_mask/ar0DB_magic_mask.png\"\n",
    "\n",
    "    for image_filename in image_filename_list:\n",
    "        image_path = os.path.join(image_dir_path, image_filename)\n",
    "        print(\"image_path = \", image_path)\n",
    "        image = Image.open(image_path)\n",
    "        if transform_image(image) is None:\n",
    "            continue\n",
    "        image = transform_image(image).unsqueeze(0).to(device)\n",
    "\n",
    "        outputs = model(image)\n",
    "        mask = torch.squeeze(torch.argmax(outputs['out'].cpu(), dim=1)).numpy()\n",
    "        #print(\"mask size = \", mask.size())\n",
    "        #print(mask)\n",
    "        if magic_mask_path:\n",
    "            mask = apply_mask(mask, magic_mask_path)\n",
    "\n",
    "        pixel_count = int(np.sum(mask == 1))\n",
    "        pixel_counts.append({'time': image_filename, 'pixel_number': pixel_count})\n",
    "\n",
    "        overlay = image.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        red_channel = overlay[:, :, 0]\n",
    "        red_channel[mask == 1] = 255\n",
    "        overlay[:, :, 0] = red_channel\n",
    "        overlay = Image.fromarray((overlay * 255).astype(np.uint8))\n",
    "        overlay.save(os.path.join(result_dir, f\"overlay_{image_filename}\"))\n",
    "    \n",
    "    date = data_dir_path.split('-')[-1]\n",
    "    with open(os.path.join(data_dir_path, f'pixel_counts_{date}.json'), 'w') as f:\n",
    "        json.dump(pixel_counts, f, indent=4)\n",
    "    return pixel_counts\n",
    "\n",
    "#image_dir = select_folder()\n",
    "image_dirs = [\"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240717\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240718\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240719\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240720\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240721\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240722\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240723\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240724\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240725\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240726\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240727\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240728\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240729\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240730\",\n",
    "              \"C:/天_11157065/NAS_data/午仔魚_屏東張詳誌/屏東張詳誌/frames-20240731\"\n",
    "             ]\n",
    "for image_dir in image_dirs:\n",
    "    print(image_dir)\n",
    "    pixel_counts = KD_inference(model_segformer, weight_dir, image_dir)\n",
    "    #C:/Users/user/Desktop/NAS_data/鱸魚/高雄黃明和/frames-20240406\n",
    "    #pixel_counts = KD_inference(model_segformer, weight_dir, 'C:/Users/user/Desktop/NAS_data/鱸魚/高雄黃明和/frames-20240407_50')\n",
    "    #print(\"Mask counts:\", pixel_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam_trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
